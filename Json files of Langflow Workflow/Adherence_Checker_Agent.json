{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-JUpMf",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "search_query",
            "id": "MongoDBAtlasVector-SPe2x",
            "inputTypes": [
              "Message"
            ],
            "type": "query"
          }
        },
        "id": "reactflow__edge-TextInput-JUpMf{œdataTypeœ:œTextInputœ,œidœ:œTextInput-JUpMfœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-MongoDBAtlasVector-SPe2x{œfieldNameœ:œsearch_queryœ,œidœ:œMongoDBAtlasVector-SPe2xœ,œinputTypesœ:[œMessageœ],œtypeœ:œqueryœ}",
        "selected": false,
        "source": "TextInput-JUpMf",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-JUpMfœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MongoDBAtlasVector-SPe2x",
        "targetHandle": "{œfieldNameœ:œsearch_queryœ,œidœ:œMongoDBAtlasVector-SPe2xœ,œinputTypesœ:[œMessageœ],œtypeœ:œqueryœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIEmbeddings",
            "id": "OpenAIEmbeddings-oM4An",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          },
          "targetHandle": {
            "fieldName": "embedding",
            "id": "MongoDBAtlasVector-SPe2x",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-OpenAIEmbeddings-oM4An{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-oM4Anœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-MongoDBAtlasVector-SPe2x{œfieldNameœ:œembeddingœ,œidœ:œMongoDBAtlasVector-SPe2xœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OpenAIEmbeddings-oM4An",
        "sourceHandle": "{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-oM4Anœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "MongoDBAtlasVector-SPe2x",
        "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œMongoDBAtlasVector-SPe2xœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "MongoDBAtlasVector",
            "id": "MongoDBAtlasVector-SPe2x",
            "name": "dataframe",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-WPWcn",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-MongoDBAtlasVector-SPe2x{œdataTypeœ:œMongoDBAtlasVectorœ,œidœ:œMongoDBAtlasVector-SPe2xœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}-ParserComponent-WPWcn{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-WPWcnœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "MongoDBAtlasVector-SPe2x",
        "sourceHandle": "{œdataTypeœ:œMongoDBAtlasVectorœ,œidœ:œMongoDBAtlasVector-SPe2xœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ParserComponent-WPWcn",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-WPWcnœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-WPWcn",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "scheduled_tasks",
            "id": "Prompt-kvdOE",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-WPWcn{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-WPWcnœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt-kvdOE{œfieldNameœ:œscheduled_tasksœ,œidœ:œPrompt-kvdOEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-WPWcn",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-WPWcnœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-kvdOE",
        "targetHandle": "{œfieldNameœ:œscheduled_tasksœ,œidœ:œPrompt-kvdOEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-rYc1b",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "Prompt-cyEOp",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-OpenAIModel-rYc1b{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-rYc1bœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-Prompt-cyEOp{œfieldNameœ:œmessageœ,œidœ:œPrompt-cyEOpœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-rYc1b",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-rYc1bœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-cyEOp",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œPrompt-cyEOpœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-JUpMf",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "patiend_id_with_name",
            "id": "Prompt-cyEOp",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-TextInput-JUpMf{œdataTypeœ:œTextInputœ,œidœ:œTextInput-JUpMfœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-cyEOp{œfieldNameœ:œpatiend_id_with_nameœ,œidœ:œPrompt-cyEOpœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-JUpMf",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-JUpMfœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-cyEOp",
        "targetHandle": "{œfieldNameœ:œpatiend_id_with_nameœ,œidœ:œPrompt-cyEOpœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-cyEOp",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-TYPUk",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-cyEOp{œdataTypeœ:œPromptœ,œidœ:œPrompt-cyEOpœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-TYPUk{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-TYPUkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-cyEOp",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-cyEOpœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-TYPUk",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-TYPUkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-TYPUk",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "ConditionalRouter-opCX3",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-OpenAIModel-TYPUk{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-TYPUkœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-opCX3{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-opCX3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-TYPUk",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-TYPUkœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-opCX3",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-opCX3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-vNeqV",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ExtractLastTelegramTextMessage-8oOyG",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-vNeqV{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-vNeqVœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-ExtractLastTelegramTextMessage-8oOyG{œfieldNameœ:œinput_valueœ,œidœ:œExtractLastTelegramTextMessage-8oOyGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-vNeqV",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-vNeqVœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ExtractLastTelegramTextMessage-8oOyG",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œExtractLastTelegramTextMessage-8oOyGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "APIRequest",
            "id": "APIRequest-s9eg1",
            "name": "data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-vNeqV",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-APIRequest-s9eg1{œdataTypeœ:œAPIRequestœ,œidœ:œAPIRequest-s9eg1œ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-ParserComponent-vNeqV{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-vNeqVœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "APIRequest-s9eg1",
        "sourceHandle": "{œdataTypeœ:œAPIRequestœ,œidœ:œAPIRequest-s9eg1œ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParserComponent-vNeqV",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-vNeqVœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ExtractLastTelegramTextMessage",
            "id": "ExtractLastTelegramTextMessage-8oOyG",
            "name": "output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "patient_response",
            "id": "Prompt-kvdOE",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ExtractLastTelegramTextMessage-8oOyG{œdataTypeœ:œExtractLastTelegramTextMessageœ,œidœ:œExtractLastTelegramTextMessage-8oOyGœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-Prompt-kvdOE{œfieldNameœ:œpatient_responseœ,œidœ:œPrompt-kvdOEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ExtractLastTelegramTextMessage-8oOyG",
        "sourceHandle": "{œdataTypeœ:œExtractLastTelegramTextMessageœ,œidœ:œExtractLastTelegramTextMessage-8oOyGœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-kvdOE",
        "targetHandle": "{œfieldNameœ:œpatient_responseœ,œidœ:œPrompt-kvdOEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-rYc1b",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-DE8uL",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-OpenAIModel-rYc1b{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-rYc1bœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-DE8uL{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-DE8uLœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OpenAIModel-rYc1b",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-rYc1bœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-DE8uL",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-DE8uLœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-rYc1b",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "FollowUpNeededChecker-Oa4vB",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-OpenAIModel-rYc1b{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-rYc1bœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-FollowUpNeededChecker-Oa4vB{œfieldNameœ:œinput_valueœ,œidœ:œFollowUpNeededChecker-Oa4vBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-rYc1b",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-rYc1bœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "FollowUpNeededChecker-Oa4vB",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œFollowUpNeededChecker-Oa4vBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "FollowUpNeededChecker",
            "id": "FollowUpNeededChecker-Oa4vB",
            "name": "output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "ConditionalRouter-opCX3",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-FollowUpNeededChecker-Oa4vB{œdataTypeœ:œFollowUpNeededCheckerœ,œidœ:œFollowUpNeededChecker-Oa4vBœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-opCX3{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-opCX3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "FollowUpNeededChecker-Oa4vB",
        "sourceHandle": "{œdataTypeœ:œFollowUpNeededCheckerœ,œidœ:œFollowUpNeededChecker-Oa4vBœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-opCX3",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-opCX3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-kvdOE",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-1qB6v",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-kvdOE{œdataTypeœ:œPromptœ,œidœ:œPrompt-kvdOEœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-1qB6v{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-1qB6vœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-kvdOE",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-kvdOEœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-1qB6v",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-1qB6vœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-ebjLt",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-rYc1b",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-ebjLt{œdataTypeœ:œPromptœ,œidœ:œPrompt-ebjLtœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-rYc1b{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-rYc1bœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-ebjLt",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-ebjLtœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-rYc1b",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-rYc1bœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-opCX3",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_text",
            "id": "ComposioSlackAPIComponent-9KXTZ",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ConditionalRouter-opCX3{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-opCX3œ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-ComposioSlackAPIComponent-9KXTZ{œfieldNameœ:œSLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_textœ,œidœ:œComposioSlackAPIComponent-9KXTZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-opCX3",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-opCX3œ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ComposioSlackAPIComponent-9KXTZ",
        "targetHandle": "{œfieldNameœ:œSLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_textœ,œidœ:œComposioSlackAPIComponent-9KXTZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-1qB6v",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "care_plan",
            "id": "Prompt-ebjLt",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__OpenAIModel-1qB6v{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-1qB6vœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-Prompt-ebjLt{œfieldNameœ:œcare_planœ,œidœ:œPrompt-ebjLtœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-1qB6v",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-1qB6vœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-ebjLt",
        "targetHandle": "{œfieldNameœ:œcare_planœ,œidœ:œPrompt-ebjLtœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "APIRequest-s9eg1",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "category": "data",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Make HTTP requests using URLs or cURL commands.",
            "display_name": "API Request",
            "documentation": "",
            "edited": false,
            "field_order": [
              "urls",
              "curl",
              "method",
              "use_curl",
              "query_params",
              "body",
              "headers",
              "timeout",
              "follow_redirects",
              "save_to_file",
              "include_httpx_metadata"
            ],
            "frozen": false,
            "icon": "Globe",
            "key": "APIRequest",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data",
                "hidden": false,
                "method": "make_requests",
                "name": "data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "hidden": false,
                "method": "as_dataframe",
                "name": "dataframe",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "body": {
                "_input_type": "TableInput",
                "advanced": true,
                "display_name": "Body",
                "dynamic": false,
                "info": "The body to send with the request as a dictionary (for POST, PATCH, PUT).",
                "input_types": [
                  "Data"
                ],
                "is_list": true,
                "list_add_label": "Add More",
                "name": "body",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": {
                  "columns": [
                    {
                      "default": "None",
                      "description": "Parameter name",
                      "disable_edit": false,
                      "display_name": "Key",
                      "edit_mode": "popover",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "key",
                      "sortable": true,
                      "type": "str"
                    },
                    {
                      "default": "None",
                      "description": "Parameter value",
                      "disable_edit": false,
                      "display_name": "Value",
                      "edit_mode": "popover",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "value",
                      "sortable": true
                    }
                  ]
                },
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": []
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import asyncio\nimport json\nimport re\nimport tempfile\nfrom datetime import datetime, timezone\nfrom pathlib import Path\nfrom typing import Any\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport aiofiles\nimport aiofiles.os as aiofiles_os\nimport httpx\nimport validators\n\nfrom langflow.base.curl.parse import parse_context\nfrom langflow.custom import Component\nfrom langflow.io import (\n    BoolInput,\n    DataInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n    StrInput,\n    TableInput,\n)\nfrom langflow.schema import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.services.deps import get_settings_service\n\n# Get settings using the service\n\n\nclass APIRequestComponent(Component):\n    display_name = \"API Request\"\n    description = \"Make HTTP requests using URLs or cURL commands.\"\n    icon = \"Globe\"\n    name = \"APIRequest\"\n\n    default_keys = [\"urls\", \"method\", \"query_params\"]\n\n    inputs = [\n        MessageTextInput(\n            name=\"urls\",\n            display_name=\"URLs\",\n            list=True,\n            info=\"Enter one or more URLs, separated by commas.\",\n            advanced=False,\n            tool_mode=True,\n        ),\n        MultilineInput(\n            name=\"curl\",\n            display_name=\"cURL\",\n            info=(\n                \"Paste a curl command to populate the fields. \"\n                \"This will fill in the dictionary fields for headers and body.\"\n            ),\n            advanced=True,\n            real_time_refresh=True,\n            tool_mode=True,\n        ),\n        DropdownInput(\n            name=\"method\",\n            display_name=\"Method\",\n            options=[\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"],\n            info=\"The HTTP method to use.\",\n            real_time_refresh=True,\n        ),\n        BoolInput(\n            name=\"use_curl\",\n            display_name=\"Use cURL\",\n            value=False,\n            info=\"Enable cURL mode to populate fields from a cURL command.\",\n            real_time_refresh=True,\n        ),\n        DataInput(\n            name=\"query_params\",\n            display_name=\"Query Parameters\",\n            info=\"The query parameters to append to the URL.\",\n            advanced=True,\n        ),\n        TableInput(\n            name=\"body\",\n            display_name=\"Body\",\n            info=\"The body to send with the request as a dictionary (for POST, PATCH, PUT).\",\n            table_schema=[\n                {\n                    \"name\": \"key\",\n                    \"display_name\": \"Key\",\n                    \"type\": \"str\",\n                    \"description\": \"Parameter name\",\n                },\n                {\n                    \"name\": \"value\",\n                    \"display_name\": \"Value\",\n                    \"description\": \"Parameter value\",\n                },\n            ],\n            value=[],\n            input_types=[\"Data\"],\n            advanced=True,\n            real_time_refresh=True,\n        ),\n        TableInput(\n            name=\"headers\",\n            display_name=\"Headers\",\n            info=\"The headers to send with the request\",\n            table_schema=[\n                {\n                    \"name\": \"key\",\n                    \"display_name\": \"Header\",\n                    \"type\": \"str\",\n                    \"description\": \"Header name\",\n                },\n                {\n                    \"name\": \"value\",\n                    \"display_name\": \"Value\",\n                    \"type\": \"str\",\n                    \"description\": \"Header value\",\n                },\n            ],\n            value=[{\"key\": \"User-Agent\", \"value\": get_settings_service().settings.user_agent}],\n            advanced=True,\n            input_types=[\"Data\"],\n            real_time_refresh=True,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            value=30,\n            info=\"The timeout to use for the request.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"follow_redirects\",\n            display_name=\"Follow Redirects\",\n            value=True,\n            info=\"Whether to follow http redirects.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"save_to_file\",\n            display_name=\"Save to File\",\n            value=False,\n            info=\"Save the API response to a temporary file\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_httpx_metadata\",\n            display_name=\"Include HTTPx Metadata\",\n            value=False,\n            info=(\n                \"Include properties such as headers, status_code, response_headers, \"\n                \"and redirection_history in the output.\"\n            ),\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"make_requests\"),\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"as_dataframe\"),\n    ]\n\n    def _parse_json_value(self, value: Any) -> Any:\n        \"\"\"Parse a value that might be a JSON string.\"\"\"\n        if not isinstance(value, str):\n            return value\n\n        try:\n            parsed = json.loads(value)\n        except json.JSONDecodeError:\n            return value\n        else:\n            return parsed\n\n    def _process_body(self, body: Any) -> dict:\n        \"\"\"Process the body input into a valid dictionary.\n\n        Args:\n            body: The body to process, can be dict, str, or list\n        Returns:\n            Processed dictionary\n        \"\"\"\n        if body is None:\n            return {}\n        if isinstance(body, dict):\n            return self._process_dict_body(body)\n        if isinstance(body, str):\n            return self._process_string_body(body)\n        if isinstance(body, list):\n            return self._process_list_body(body)\n\n        return {}\n\n    def _process_dict_body(self, body: dict) -> dict:\n        \"\"\"Process dictionary body by parsing JSON values.\"\"\"\n        return {k: self._parse_json_value(v) for k, v in body.items()}\n\n    def _process_string_body(self, body: str) -> dict:\n        \"\"\"Process string body by attempting JSON parse.\"\"\"\n        try:\n            return self._process_body(json.loads(body))\n        except json.JSONDecodeError:\n            return {\"data\": body}\n\n    def _process_list_body(self, body: list) -> dict:\n        \"\"\"Process list body by converting to key-value dictionary.\"\"\"\n        processed_dict = {}\n\n        try:\n            for item in body:\n                if not self._is_valid_key_value_item(item):\n                    continue\n\n                key = item[\"key\"]\n                value = self._parse_json_value(item[\"value\"])\n                processed_dict[key] = value\n\n        except (KeyError, TypeError, ValueError) as e:\n            self.log(f\"Failed to process body list: {e}\")\n            return {}  # Return empty dictionary instead of None\n\n        return processed_dict\n\n    def _is_valid_key_value_item(self, item: Any) -> bool:\n        \"\"\"Check if an item is a valid key-value dictionary.\"\"\"\n        return isinstance(item, dict) and \"key\" in item and \"value\" in item\n\n    def parse_curl(self, curl: str, build_config: dotdict) -> dotdict:\n        \"\"\"Parse a cURL command and update build configuration.\n\n        Args:\n            curl: The cURL command to parse\n            build_config: The build configuration to update\n        Returns:\n            Updated build configuration\n        \"\"\"\n        try:\n            parsed = parse_context(curl)\n\n            # Update basic configuration\n            build_config[\"urls\"][\"value\"] = [parsed.url]\n            build_config[\"method\"][\"value\"] = parsed.method.upper()\n            build_config[\"headers\"][\"advanced\"] = True\n            build_config[\"body\"][\"advanced\"] = True\n\n            # Process headers\n            headers_list = [{\"key\": k, \"value\": v} for k, v in parsed.headers.items()]\n            build_config[\"headers\"][\"value\"] = headers_list\n\n            if headers_list:\n                build_config[\"headers\"][\"advanced\"] = False\n\n            # Process body data\n            if not parsed.data:\n                build_config[\"body\"][\"value\"] = []\n            elif parsed.data:\n                try:\n                    json_data = json.loads(parsed.data)\n                    if isinstance(json_data, dict):\n                        body_list = [\n                            {\"key\": k, \"value\": json.dumps(v) if isinstance(v, dict | list) else str(v)}\n                            for k, v in json_data.items()\n                        ]\n                        build_config[\"body\"][\"value\"] = body_list\n                        build_config[\"body\"][\"advanced\"] = False\n                    else:\n                        build_config[\"body\"][\"value\"] = [{\"key\": \"data\", \"value\": json.dumps(json_data)}]\n                        build_config[\"body\"][\"advanced\"] = False\n                except json.JSONDecodeError:\n                    build_config[\"body\"][\"value\"] = [{\"key\": \"data\", \"value\": parsed.data}]\n                    build_config[\"body\"][\"advanced\"] = False\n\n        except Exception as exc:\n            msg = f\"Error parsing curl: {exc}\"\n            self.log(msg)\n            raise ValueError(msg) from exc\n\n        return build_config\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name == \"use_curl\" and field_value:\n            # if we remove field value from validation, this gets validated every time\n            build_config = self._update_curl_mode(build_config, use_curl=field_value)\n\n            # If curl is not used, we don't need to reset the fields\n            if not self.use_curl:\n                return build_config\n\n            # Fields that should not be reset\n            preserve_fields = {\"timeout\", \"follow_redirects\", \"save_to_file\", \"include_httpx_metadata\", \"use_curl\"}\n\n            # Mapping between input types and their reset values\n            type_reset_mapping = {\n                TableInput: [],\n                BoolInput: False,\n                IntInput: 0,\n                FloatInput: 0.0,\n                MessageTextInput: \"\",\n                StrInput: \"\",\n                MultilineInput: \"\",\n                DropdownInput: \"GET\",\n                DataInput: {},\n            }\n\n            for input_field in self.inputs:\n                # Only reset if field is not in preserve list\n                if input_field.name not in preserve_fields:\n                    reset_value = type_reset_mapping.get(type(input_field), None)\n                    build_config[input_field.name][\"value\"] = reset_value\n                    self.log(f\"Reset field {input_field.name} to {reset_value}\")\n            # Don't try to parse the boolean value as a curl command\n            return build_config\n        if field_name == \"method\" and not self.use_curl:\n            build_config = self._update_method_fields(build_config, field_value)\n        elif field_name == \"curl\" and self.use_curl and field_value:\n            # Not reachable, because we don't have a way to update\n            # the curl field, self.use_curl is set after the build_config is created\n            build_config = self.parse_curl(field_value, build_config)\n        return build_config\n\n    def _update_curl_mode(self, build_config: dotdict, *, use_curl: bool) -> dotdict:\n        always_visible = [\"method\", \"use_curl\"]\n\n        for field in self.inputs:\n            field_name = field.name\n            field_config = build_config.get(field_name)\n            if isinstance(field_config, dict):\n                if field_name in always_visible:\n                    field_config[\"advanced\"] = False\n                elif field_name == \"urls\":\n                    field_config[\"advanced\"] = use_curl\n                elif field_name == \"curl\":\n                    field_config[\"advanced\"] = not use_curl\n                    field_config[\"real_time_refresh\"] = use_curl\n                elif field_name in {\"body\", \"headers\"}:\n                    field_config[\"advanced\"] = True  # Always keep body and headers in advanced when use_curl is False\n                else:\n                    field_config[\"advanced\"] = use_curl or field_config.get(\"advanced\")\n            else:\n                self.log(f\"Expected dict for build_config[{field_name}], got {type(field_config).__name__}\")\n\n        if not use_curl:\n            current_method = build_config.get(\"method\", {}).get(\"value\", \"GET\")\n            build_config = self._update_method_fields(build_config, current_method)\n\n        return build_config\n\n    def _update_method_fields(self, build_config: dotdict, method: str) -> dotdict:\n        common_fields = [\n            \"urls\",\n            \"method\",\n            \"use_curl\",\n        ]\n\n        always_advanced_fields = [\n            \"body\",\n            \"headers\",\n            \"timeout\",\n            \"follow_redirects\",\n            \"save_to_file\",\n            \"include_httpx_metadata\",\n        ]\n\n        body_fields = [\"body\"]\n\n        for field in self.inputs:\n            field_name = field.name\n            field_config = build_config.get(field_name)\n            if isinstance(field_config, dict):\n                if field_name in common_fields:\n                    field_config[\"advanced\"] = False\n                elif field_name in body_fields:\n                    field_config[\"advanced\"] = method not in {\"POST\", \"PUT\", \"PATCH\"}\n                elif field_name in always_advanced_fields:\n                    field_config[\"advanced\"] = True\n            else:\n                self.log(f\"Expected dict for build_config[{field_name}], got {type(field_config).__name__}\")\n\n        return build_config\n\n    async def make_request(\n        self,\n        client: httpx.AsyncClient,\n        method: str,\n        url: str,\n        headers: dict | None = None,\n        body: Any = None,\n        timeout: int = 5,\n        *,\n        follow_redirects: bool = True,\n        save_to_file: bool = False,\n        include_httpx_metadata: bool = False,\n    ) -> Data:\n        method = method.upper()\n        if method not in {\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"}:\n            msg = f\"Unsupported method: {method}\"\n            raise ValueError(msg)\n\n        # Process body using the new helper method\n        processed_body = self._process_body(body)\n        redirection_history = []\n\n        try:\n            response = await client.request(\n                method,\n                url,\n                headers=headers,\n                json=processed_body,\n                timeout=timeout,\n                follow_redirects=follow_redirects,\n            )\n\n            redirection_history = [\n                {\n                    \"url\": redirect.headers.get(\"Location\", str(redirect.url)),\n                    \"status_code\": redirect.status_code,\n                }\n                for redirect in response.history\n            ]\n\n            is_binary, file_path = await self._response_info(response, with_file_path=save_to_file)\n            response_headers = self._headers_to_dict(response.headers)\n\n            metadata: dict[str, Any] = {\n                \"source\": url,\n            }\n\n            if save_to_file:\n                mode = \"wb\" if is_binary else \"w\"\n                encoding = response.encoding if mode == \"w\" else None\n                if file_path:\n                    # Ensure parent directory exists\n                    await aiofiles_os.makedirs(file_path.parent, exist_ok=True)\n                    if is_binary:\n                        async with aiofiles.open(file_path, \"wb\") as f:\n                            await f.write(response.content)\n                            await f.flush()\n                    else:\n                        async with aiofiles.open(file_path, \"w\", encoding=encoding) as f:\n                            await f.write(response.text)\n                            await f.flush()\n                    metadata[\"file_path\"] = str(file_path)\n\n                if include_httpx_metadata:\n                    metadata.update(\n                        {\n                            \"headers\": headers,\n                            \"status_code\": response.status_code,\n                            \"response_headers\": response_headers,\n                            **({\"redirection_history\": redirection_history} if redirection_history else {}),\n                        }\n                    )\n                return Data(data=metadata)\n\n            if is_binary:\n                result = response.content\n            else:\n                try:\n                    result = response.json()\n                except json.JSONDecodeError:\n                    self.log(\"Failed to decode JSON response\")\n                    result = response.text.encode(\"utf-8\")\n\n            metadata.update({\"result\": result})\n\n            if include_httpx_metadata:\n                metadata.update(\n                    {\n                        \"headers\": headers,\n                        \"status_code\": response.status_code,\n                        \"response_headers\": response_headers,\n                        **({\"redirection_history\": redirection_history} if redirection_history else {}),\n                    }\n                )\n            return Data(data=metadata)\n        except httpx.TimeoutException:\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": 408,\n                    \"error\": \"Request timed out\",\n                },\n            )\n        except Exception as exc:  # noqa: BLE001\n            self.log(f\"Error making request to {url}\")\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": 500,\n                    \"error\": str(exc),\n                    **({\"redirection_history\": redirection_history} if redirection_history else {}),\n                },\n            )\n\n    def add_query_params(self, url: str, params: dict) -> str:\n        url_parts = list(urlparse(url))\n        query = dict(parse_qsl(url_parts[4]))\n        query.update(params)\n        url_parts[4] = urlencode(query)\n        return urlunparse(url_parts)\n\n    async def make_requests(self) -> list[Data]:\n        method = self.method\n        urls = [url.strip() for url in self.urls if url.strip()]\n        headers = self.headers or {}\n        body = self.body or {}\n        timeout = self.timeout\n        follow_redirects = self.follow_redirects\n        save_to_file = self.save_to_file\n        include_httpx_metadata = self.include_httpx_metadata\n\n        if self.use_curl and self.curl:\n            self._build_config = self.parse_curl(self.curl, dotdict())\n\n        invalid_urls = [url for url in urls if not validators.url(url)]\n        if invalid_urls:\n            msg = f\"Invalid URLs provided: {invalid_urls}\"\n            raise ValueError(msg)\n\n        if isinstance(self.query_params, str):\n            query_params = dict(parse_qsl(self.query_params))\n        else:\n            query_params = self.query_params.data if self.query_params else {}\n\n        # Process headers here\n        headers = self._process_headers(headers)\n\n        # Process body\n        body = self._process_body(body)\n\n        bodies = [body] * len(urls)\n\n        urls = [self.add_query_params(url, query_params) for url in urls]\n\n        async with httpx.AsyncClient() as client:\n            results = await asyncio.gather(\n                *[\n                    self.make_request(\n                        client,\n                        method,\n                        u,\n                        headers,\n                        rec,\n                        timeout,\n                        follow_redirects=follow_redirects,\n                        save_to_file=save_to_file,\n                        include_httpx_metadata=include_httpx_metadata,\n                    )\n                    for u, rec in zip(urls, bodies, strict=False)\n                ]\n            )\n        self.status = results\n        return results\n\n    async def _response_info(\n        self, response: httpx.Response, *, with_file_path: bool = False\n    ) -> tuple[bool, Path | None]:\n        \"\"\"Determine the file path and whether the response content is binary.\n\n        Args:\n            response (Response): The HTTP response object.\n            with_file_path (bool): Whether to save the response content to a file.\n\n        Returns:\n            Tuple[bool, Path | None]:\n                A tuple containing a boolean indicating if the content is binary and the full file path (if applicable).\n        \"\"\"\n        content_type = response.headers.get(\"Content-Type\", \"\")\n        is_binary = \"application/octet-stream\" in content_type or \"application/binary\" in content_type\n\n        if not with_file_path:\n            return is_binary, None\n\n        component_temp_dir = Path(tempfile.gettempdir()) / self.__class__.__name__\n\n        # Create directory asynchronously\n        await aiofiles_os.makedirs(component_temp_dir, exist_ok=True)\n\n        filename = None\n        if \"Content-Disposition\" in response.headers:\n            content_disposition = response.headers[\"Content-Disposition\"]\n            filename_match = re.search(r'filename=\"(.+?)\"', content_disposition)\n            if filename_match:\n                extracted_filename = filename_match.group(1)\n                filename = extracted_filename\n\n        # Step 3: Infer file extension or use part of the request URL if no filename\n        if not filename:\n            # Extract the last segment of the URL path\n            url_path = urlparse(str(response.request.url) if response.request else \"\").path\n            base_name = Path(url_path).name  # Get the last segment of the path\n            if not base_name:  # If the path ends with a slash or is empty\n                base_name = \"response\"\n\n            # Infer file extension\n            content_type_to_extension = {\n                \"text/plain\": \".txt\",\n                \"application/json\": \".json\",\n                \"image/jpeg\": \".jpg\",\n                \"image/png\": \".png\",\n                \"application/octet-stream\": \".bin\",\n            }\n            extension = content_type_to_extension.get(content_type, \".bin\" if is_binary else \".txt\")\n            filename = f\"{base_name}{extension}\"\n\n        # Step 4: Define the full file path\n        file_path = component_temp_dir / filename\n\n        # Step 5: Check if file exists asynchronously and handle accordingly\n        try:\n            # Try to create the file exclusively (x mode) to check existence\n            async with aiofiles.open(file_path, \"x\") as _:\n                pass  # File created successfully, we can use this path\n        except FileExistsError:\n            # If file exists, append a timestamp to the filename\n            timestamp = datetime.now(timezone.utc).strftime(\"%Y%m%d%H%M%S%f\")\n            file_path = component_temp_dir / f\"{timestamp}-{filename}\"\n\n        return is_binary, file_path\n\n    def _headers_to_dict(self, headers: httpx.Headers) -> dict[str, str]:\n        \"\"\"Convert HTTP headers to a dictionary with lowercased keys.\"\"\"\n        return {k.lower(): v for k, v in headers.items()}\n\n    def _process_headers(self, headers: Any) -> dict:\n        \"\"\"Process the headers input into a valid dictionary.\n\n        Args:\n            headers: The headers to process, can be dict, str, or list\n        Returns:\n            Processed dictionary\n        \"\"\"\n        if headers is None:\n            return {}\n        if isinstance(headers, dict):\n            return headers\n        if isinstance(headers, list):\n            processed_headers = {}\n            try:\n                for item in headers:\n                    if not self._is_valid_key_value_item(item):\n                        continue\n                    key = item[\"key\"]\n                    value = item[\"value\"]\n                    processed_headers[key] = value\n            except (KeyError, TypeError, ValueError) as e:\n                self.log(f\"Failed to process headers list: {e}\")\n                return {}  # Return empty dictionary instead of None\n            return processed_headers\n        return {}\n\n    async def as_dataframe(self) -> DataFrame:\n        \"\"\"Convert the API response data into a DataFrame.\n\n        Returns:\n            DataFrame: A DataFrame containing the API response data.\n        \"\"\"\n        data = await self.make_requests()\n        return DataFrame(data)\n"
              },
              "curl": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "cURL",
                "dynamic": false,
                "info": "Paste a curl command to populate the fields. This will fill in the dictionary fields for headers and body.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "curl",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "follow_redirects": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Follow Redirects",
                "dynamic": false,
                "info": "Whether to follow http redirects.",
                "list": false,
                "list_add_label": "Add More",
                "name": "follow_redirects",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "headers": {
                "_input_type": "TableInput",
                "advanced": true,
                "display_name": "Headers",
                "dynamic": false,
                "info": "The headers to send with the request",
                "input_types": [
                  "Data"
                ],
                "is_list": true,
                "list_add_label": "Add More",
                "name": "headers",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": {
                  "columns": [
                    {
                      "default": "None",
                      "description": "Header name",
                      "disable_edit": false,
                      "display_name": "Header",
                      "edit_mode": "popover",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "key",
                      "sortable": true,
                      "type": "str"
                    },
                    {
                      "default": "None",
                      "description": "Header value",
                      "disable_edit": false,
                      "display_name": "Value",
                      "edit_mode": "popover",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "value",
                      "sortable": true,
                      "type": "str"
                    }
                  ]
                },
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": []
              },
              "include_httpx_metadata": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Include HTTPx Metadata",
                "dynamic": false,
                "info": "Include properties such as headers, status_code, response_headers, and redirection_history in the output.",
                "list": false,
                "list_add_label": "Add More",
                "name": "include_httpx_metadata",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "method": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Method",
                "dynamic": false,
                "info": "The HTTP method to use.",
                "name": "method",
                "options": [
                  "GET",
                  "POST",
                  "PATCH",
                  "PUT",
                  "DELETE"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "GET"
              },
              "query_params": {
                "_input_type": "DataInput",
                "advanced": true,
                "display_name": "Query Parameters",
                "dynamic": false,
                "info": "The query parameters to append to the URL.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "query_params",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": {}
              },
              "save_to_file": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Save to File",
                "dynamic": false,
                "info": "Save the API response to a temporary file",
                "list": false,
                "list_add_label": "Add More",
                "name": "save_to_file",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout to use for the request.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 30
              },
              "urls": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "URLs",
                "dynamic": false,
                "info": "Enter one or more URLs, separated by commas.",
                "input_types": [
                  "Message"
                ],
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "urls",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": [
                  "https://api.telegram.org/bot8058993131:AAHSrMiaQWlh0qN_hOWzbxmGn4XG-K3TzI0/getUpdates"
                ]
              },
              "use_curl": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Use cURL",
                "dynamic": false,
                "info": "Enable cURL mode to populate fields from a cURL command.",
                "list": false,
                "list_add_label": "Add More",
                "name": "use_curl",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "APIRequest"
        },
        "id": "APIRequest-s9eg1",
        "measured": {
          "height": 512,
          "width": 320
        },
        "position": {
          "x": -35.438149024064614,
          "y": 208.6770027592346
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-JUpMf",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "inputs",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get text inputs from the Playground.",
            "display_name": "Text Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "key": "TextInput",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.0020353564437605998,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "1024 and Abhishek Soni"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "id": "TextInput-JUpMf",
        "measured": {
          "height": 229,
          "width": 320
        },
        "position": {
          "x": -184.35254670258212,
          "y": 875.861989142603
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "MongoDBAtlasVector-SPe2x",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "category": "vectorstores",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "MongoDB Atlas Vector Store with search capabilities",
            "display_name": "MongoDB Atlas",
            "documentation": "",
            "edited": false,
            "field_order": [
              "mongodb_atlas_cluster_uri",
              "enable_mtls",
              "mongodb_atlas_client_cert",
              "db_name",
              "collection_name",
              "index_name",
              "ingest_data",
              "search_query",
              "should_cache_vector_store",
              "insert_mode",
              "embedding",
              "number_of_results",
              "index_field",
              "filter_field",
              "number_dimensions",
              "similarity",
              "quantization"
            ],
            "frozen": false,
            "icon": "MongoDB",
            "key": "MongoDBAtlasVector",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Results",
                "method": "search_documents",
                "name": "search_results",
                "required_inputs": [
                  "collection_name",
                  "db_name",
                  "enable_mtls",
                  "index_field",
                  "index_name",
                  "mongodb_atlas_cluster_uri",
                  "number_dimensions"
                ],
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "hidden": false,
                "method": "as_dataframe",
                "name": "dataframe",
                "required_inputs": [],
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.0005559042572704037,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import tempfile\nimport time\n\nimport certifi\nfrom langchain_community.vectorstores import MongoDBAtlasVectorSearch\nfrom pymongo.collection import Collection\nfrom pymongo.operations import SearchIndexModel\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import BoolInput, DropdownInput, HandleInput, IntInput, SecretStrInput, StrInput\nfrom langflow.schema import Data\n\n\nclass MongoVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"MongoDB Atlas\"\n    description = \"MongoDB Atlas Vector Store with search capabilities\"\n    name = \"MongoDBAtlasVector\"\n    icon = \"MongoDB\"\n    INSERT_MODES = [\"append\", \"overwrite\"]\n    SIMILARITY_OPTIONS = [\"cosine\", \"euclidean\", \"dotProduct\"]\n    QUANTIZATION_OPTIONS = [\"scalar\", \"binary\"]\n    inputs = [\n        SecretStrInput(name=\"mongodb_atlas_cluster_uri\", display_name=\"MongoDB Atlas Cluster URI\", required=True),\n        BoolInput(name=\"enable_mtls\", display_name=\"Enable mTLS\", value=False, advanced=True, required=True),\n        SecretStrInput(\n            name=\"mongodb_atlas_client_cert\",\n            display_name=\"MongoDB Atlas Combined Client Certificate\",\n            required=False,\n            info=\"Client Certificate combined with the private key in the following format:\\n \"\n            \"-----BEGIN PRIVATE KEY-----\\n...\\n -----END PRIVATE KEY-----\\n-----BEGIN CERTIFICATE-----\\n\"\n            \"...\\n-----END CERTIFICATE-----\\n\",\n        ),\n        StrInput(name=\"db_name\", display_name=\"Database Name\", required=True),\n        StrInput(name=\"collection_name\", display_name=\"Collection Name\", required=True),\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            required=True,\n            info=\"The name of Atlas Search index, it should be a Vector Search.\",\n        ),\n        *LCVectorStoreComponent.inputs,\n        DropdownInput(\n            name=\"insert_mode\",\n            display_name=\"Insert Mode\",\n            options=INSERT_MODES,\n            value=INSERT_MODES[0],\n            info=\"How to insert new documents into the collection.\",\n            advanced=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n        StrInput(\n            name=\"index_field\",\n            display_name=\"Index Field\",\n            advanced=True,\n            required=True,\n            info=\"The field to index.\",\n            value=\"embedding\",\n        ),\n        StrInput(\n            name=\"filter_field\", display_name=\"Filter Field\", advanced=True, info=\"The field to filter the index.\"\n        ),\n        IntInput(\n            name=\"number_dimensions\",\n            display_name=\"Number of Dimensions\",\n            info=\"Embedding Context Length.\",\n            value=1536,\n            advanced=True,\n            required=True,\n        ),\n        DropdownInput(\n            name=\"similarity\",\n            display_name=\"Similarity\",\n            options=SIMILARITY_OPTIONS,\n            value=SIMILARITY_OPTIONS[0],\n            info=\"The method used to measure the similarity between vectors.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"quantization\",\n            display_name=\"Quantization\",\n            options=QUANTIZATION_OPTIONS,\n            value=None,\n            info=\"Quantization reduces memory costs converting 32-bit floats to smaller data types\",\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> MongoDBAtlasVectorSearch:\n        try:\n            from pymongo import MongoClient\n        except ImportError as e:\n            msg = \"Please install pymongo to use MongoDB Atlas Vector Store\"\n            raise ImportError(msg) from e\n\n        # Create temporary files for the client certificate\n        if self.enable_mtls:\n            client_cert_path = None\n            try:\n                client_cert = self.mongodb_atlas_client_cert.replace(\" \", \"\\n\")\n                client_cert = client_cert.replace(\"-----BEGIN\\nPRIVATE\\nKEY-----\", \"-----BEGIN PRIVATE KEY-----\")\n                client_cert = client_cert.replace(\n                    \"-----END\\nPRIVATE\\nKEY-----\\n-----BEGIN\\nCERTIFICATE-----\",\n                    \"-----END PRIVATE KEY-----\\n-----BEGIN CERTIFICATE-----\",\n                )\n                client_cert = client_cert.replace(\"-----END\\nCERTIFICATE-----\", \"-----END CERTIFICATE-----\")\n                with tempfile.NamedTemporaryFile(delete=False) as client_cert_file:\n                    client_cert_file.write(client_cert.encode(\"utf-8\"))\n                    client_cert_path = client_cert_file.name\n\n            except Exception as e:\n                msg = f\"Failed to write certificate to temporary file: {e}\"\n                raise ValueError(msg) from e\n\n        try:\n            mongo_client: MongoClient = (\n                MongoClient(\n                    self.mongodb_atlas_cluster_uri,\n                    tls=True,\n                    tlsCertificateKeyFile=client_cert_path,\n                    tlsCAFile=certifi.where(),\n                )\n                if self.enable_mtls\n                else MongoClient(self.mongodb_atlas_cluster_uri)\n            )\n\n            collection = mongo_client[self.db_name][self.collection_name]\n\n        except Exception as e:\n            msg = f\"Failed to connect to MongoDB Atlas: {e}\"\n            raise ValueError(msg) from e\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            self.__insert_mode(collection)\n\n            return MongoDBAtlasVectorSearch.from_documents(\n                documents=documents, embedding=self.embedding, collection=collection, index_name=self.index_name\n            )\n        return MongoDBAtlasVectorSearch(embedding=self.embedding, collection=collection, index_name=self.index_name)\n\n    def search_documents(self) -> list[Data]:\n        from bson.objectid import ObjectId\n\n        vector_store = self.build_vector_store()\n\n        self.verify_search_index(vector_store._collection)\n\n        if self.search_query and isinstance(self.search_query, str):\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n            for doc in docs:\n                doc.metadata = {\n                    key: str(value) if isinstance(value, ObjectId) else value for key, value in doc.metadata.items()\n                }\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n\n    def __insert_mode(self, collection: Collection) -> None:\n        if self.insert_mode == \"overwrite\":\n            collection.delete_many({})  # Delete all documents while preserving collection structure\n\n    def verify_search_index(self, collection: Collection) -> None:\n        \"\"\"Verify if the search index exists, if not, create it.\n\n        Args:\n            collection (Collection): The collection to verify the search index on.\n        \"\"\"\n        indexes = collection.list_search_indexes()\n\n        index_names_types = {idx[\"name\"]: idx[\"type\"] for idx in indexes}\n        index_names = list(index_names_types.keys())\n        index_type = index_names_types.get(self.index_name)\n        if self.index_name not in index_names and index_type != \"vectorSearch\":\n            collection.create_search_index(self.__create_index_definition())\n\n            time.sleep(20)  # Give some time for index to be ready\n\n    def __create_index_definition(self) -> SearchIndexModel:\n        fields = [\n            {\n                \"type\": \"vector\",\n                \"path\": self.index_field,\n                \"numDimensions\": self.number_dimensions,\n                \"similarity\": self.similarity,\n                \"quantization\": self.quantization,\n            }\n        ]\n        if self.filter_field:\n            fields.append({\"type\": \"filter\", \"path\": self.filter_field})\n        return SearchIndexModel(definition={\"fields\": fields}, name=self.index_name, type=\"vectorSearch\")\n"
              },
              "collection_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Collection Name",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "collection_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Scheduled_Tasks"
              },
              "db_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Database Name",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "db_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Care_Plan"
              },
              "embedding": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Embedding",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Embeddings"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "embedding",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "enable_mtls": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Enable mTLS",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "enable_mtls",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "filter_field": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Filter Field",
                "dynamic": false,
                "info": "The field to filter the index.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "filter_field",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "index_field": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Index Field",
                "dynamic": false,
                "info": "The field to index.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "index_field",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "embedding"
              },
              "index_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Index Name",
                "dynamic": false,
                "info": "The name of Atlas Search index, it should be a Vector Search.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "index_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "index"
              },
              "ingest_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Ingest Data",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data",
                  "DataFrame"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "ingest_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "insert_mode": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Insert Mode",
                "dynamic": false,
                "info": "How to insert new documents into the collection.",
                "name": "insert_mode",
                "options": [
                  "append",
                  "overwrite"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "append"
              },
              "mongodb_atlas_client_cert": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "MongoDB Atlas Combined Client Certificate",
                "dynamic": false,
                "info": "Client Certificate combined with the private key in the following format:\n -----BEGIN PRIVATE KEY-----\n...\n -----END PRIVATE KEY-----\n-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----\n",
                "input_types": [],
                "load_from_db": false,
                "name": "mongodb_atlas_client_cert",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "mongodb_atlas_cluster_uri": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "MongoDB Atlas Cluster URI",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "mongodb_atlas_cluster_uri",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "number_dimensions": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Dimensions",
                "dynamic": false,
                "info": "Embedding Context Length.",
                "list": false,
                "list_add_label": "Add More",
                "name": "number_dimensions",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1536
              },
              "number_of_results": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Results",
                "dynamic": false,
                "info": "Number of results to return.",
                "list": false,
                "list_add_label": "Add More",
                "name": "number_of_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "quantization": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Quantization",
                "dynamic": false,
                "info": "Quantization reduces memory costs converting 32-bit floats to smaller data types",
                "name": "quantization",
                "options": [
                  "scalar",
                  "binary"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str"
              },
              "search_query": {
                "_input_type": "QueryInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "Enter a query to run a similarity search.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "search_query",
                "placeholder": "Enter a query...",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "query",
                "value": ""
              },
              "should_cache_vector_store": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Cache Vector Store",
                "dynamic": false,
                "info": "If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_cache_vector_store",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "similarity": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Similarity",
                "dynamic": false,
                "info": "The method used to measure the similarity between vectors.",
                "name": "similarity",
                "options": [
                  "cosine",
                  "euclidean",
                  "dotProduct"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "cosine"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "MongoDBAtlasVector"
        },
        "id": "MongoDBAtlasVector-SPe2x",
        "measured": {
          "height": 800,
          "width": 320
        },
        "position": {
          "x": 523.8601857520905,
          "y": 559.7377695389663
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OpenAIEmbeddings-oM4An",
          "node": {
            "base_classes": [
              "Embeddings"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate embeddings using OpenAI models.",
            "display_name": "OpenAI Embeddings",
            "documentation": "",
            "edited": false,
            "field_order": [
              "default_headers",
              "default_query",
              "chunk_size",
              "client",
              "deployment",
              "embedding_ctx_length",
              "max_retries",
              "model",
              "model_kwargs",
              "openai_api_key",
              "openai_api_base",
              "openai_api_type",
              "openai_api_version",
              "openai_organization",
              "openai_proxy",
              "request_timeout",
              "show_progress_bar",
              "skip_empty",
              "tiktoken_model_name",
              "tiktoken_enable",
              "dimensions"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Embeddings",
                "hidden": false,
                "method": "build_embeddings",
                "name": "embeddings",
                "required_inputs": [
                  "openai_api_key"
                ],
                "selected": "Embeddings",
                "tool_mode": true,
                "types": [
                  "Embeddings"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "chunk_size": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Chunk Size",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "chunk_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1000
              },
              "client": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Client",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "client",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_openai import OpenAIEmbeddings\n\nfrom langflow.base.embeddings.model import LCEmbeddingsModel\nfrom langflow.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\", required=True),\n        MessageTextInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        MessageTextInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. \"\n            \"Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            client=self.client or None,\n            model=self.model,\n            dimensions=self.dimensions or None,\n            deployment=self.deployment or None,\n            api_version=self.openai_api_version or None,\n            base_url=self.openai_api_base or None,\n            openai_api_type=self.openai_api_type or None,\n            openai_proxy=self.openai_proxy or None,\n            embedding_ctx_length=self.embedding_ctx_length,\n            api_key=self.openai_api_key or None,\n            organization=self.openai_organization or None,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            max_retries=self.max_retries,\n            timeout=self.request_timeout or None,\n            tiktoken_enabled=self.tiktoken_enable,\n            tiktoken_model_name=self.tiktoken_model_name or None,\n            show_progress_bar=self.show_progress_bar,\n            model_kwargs=self.model_kwargs,\n            skip_empty=self.skip_empty,\n            default_headers=self.default_headers or None,\n            default_query=self.default_query or None,\n        )\n"
              },
              "default_headers": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Default Headers",
                "dynamic": false,
                "info": "Default headers to use for the API request.",
                "list": false,
                "list_add_label": "Add More",
                "name": "default_headers",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "default_query": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Default Query",
                "dynamic": false,
                "info": "Default query parameters to use for the API request.",
                "list": false,
                "list_add_label": "Add More",
                "name": "default_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "deployment": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Deployment",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "deployment",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "dimensions": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Dimensions",
                "dynamic": false,
                "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                "list": false,
                "list_add_label": "Add More",
                "name": "dimensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "embedding_ctx_length": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Embedding Context Length",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "embedding_ctx_length",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1536
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 3
              },
              "model": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model",
                "dynamic": false,
                "info": "",
                "name": "model",
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "text-embedding-3-small"
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "openai_api_base": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "openai_api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "openai_api_type": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI API Type",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_type",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_api_version": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI API Version",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_version",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_organization": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI Organization",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_organization",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_proxy": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI Proxy",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_proxy",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "request_timeout": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Request Timeout",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "request_timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": ""
              },
              "show_progress_bar": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Show Progress Bar",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "show_progress_bar",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "skip_empty": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Skip Empty",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "skip_empty",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "tiktoken_enable": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "TikToken Enable",
                "dynamic": false,
                "info": "If False, you must have transformers installed.",
                "list": false,
                "list_add_label": "Add More",
                "name": "tiktoken_enable",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "tiktoken_model_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "TikToken Model Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tiktoken_model_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "OpenAIEmbeddings"
        },
        "dragging": false,
        "id": "OpenAIEmbeddings-oM4An",
        "measured": {
          "height": 312,
          "width": 320
        },
        "position": {
          "x": -17.585401001592544,
          "y": 1249.6965762451764
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-WPWcn",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Format a DataFrame or Data object into text using a template. Enable 'Stringify' to convert input into a readable string instead.",
            "display_name": "Parser",
            "documentation": "",
            "edited": false,
            "field_order": [
              "mode",
              "pattern",
              "input_data",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "hidden": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.io import (\n    BoolInput,\n    HandleInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n    TabInput,\n)\nfrom langflow.schema import Data, DataFrame\nfrom langflow.schema.message import Message\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = (\n        \"Format a DataFrame or Data object into text using a template. \"\n        \"Enable 'Stringify' to convert input into a readable string instead.\"\n    )\n    icon = \"braces\"\n\n    inputs = [\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                return json.dumps(data.data)\n            if isinstance(data, DataFrame):\n                if hasattr(self, \"clean_data\") and self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([self._safe_convert(item) for item in self.input_data])\n        else:\n            result = self._safe_convert(self.input_data)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "id": "ParserComponent-WPWcn",
        "measured": {
          "height": 394,
          "width": 320
        },
        "position": {
          "x": 1032.2377572913783,
          "y": 787.1508084145804
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt-kvdOE",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "scheduled_tasks",
                "patient_response"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": false,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "patient_response": {
                "advanced": false,
                "display_name": "patient_response",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "patient_response",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "scheduled_tasks": {
                "advanced": false,
                "display_name": "scheduled_tasks",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "scheduled_tasks",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "TaskResponseParser Agent - System Prompt\n\nYOU ARE \"TaskResponseParser\", AN INTELLIGENT AGENT THAT PROCESSES PATIENT RESPONSES TO THEIR SCHEDULED DAILY TASKS AND CONVERTS THEM INTO STRUCTURED JSON OUTPUT.\n\nPRIMARY OBJECTIVE\nParse patient responses about task completion and generate a clean JSON output mapping each scheduled task to its completion status.\n\nINPUT STRUCTURE\nYou will receive scheduled tasks in this format understand the daily reminder array like take the tasks scheduled :\n{scheduled_tasks}\n\nPatient response to the scheduled tasks please take this as the patients reposponse please take care that the patient is replying sequentially according to the taks scheduled :\n{patient_response}\n\nRESPONSE FORMATS & PARSING RULES\n\nFormat 1: Sequential Yes/No Responses (MOST COMMON)\nInput Examples:\n- Yes    No → First task: Yes, Second task: No\n- NO    NO → Both tasks: No\n- Yes   Yes  No → Three tasks: Yes, Yes, No\n\nCritical Rule: Map responses to tasks in EXACT CHRONOLOGICAL ORDER of scheduled tasks.\n\nFormat 2: Simple Symbols\n- ✅❌ → First task: Yes, Second task: No\n- ❌❌ → Both tasks: No\n\nFormat 3: Conversational\n- \"I did the first one but missed the second\" → First: Yes, Second: No\n\nCOMPLETION STATUS MAPPING\n\nYES/COMPLETED Indicators:\n- \"Yes\", \"YES\", \"yes\"\n- \"✅\", \"Done\", \"Completed\"\n- \"I did\", \"Took it\"\n\nNO/MISSED Indicators:\n- \"No\", \"NO\", \"no\"\n- \"❌\", \"Missed\", \"Forgot\"\n- \"Didn't do\", \"Skipped\"\n\nPARSING ALGORITHM\n\nSTEP 1: Count scheduled tasks\nExtract all tasks from  input and count them.\n\nSTEP 2: Parse patient response\n- Split response by newlines (\\n) or spaces for sequential format\n- Clean whitespace and normalize case\n- Convert symbols to Yes/No\n\nSTEP 3: Map responses to tasks\n- Map first response to first chronological task\n- Map second response to second chronological task\n- Continue in order\n\nSTEP 4: Handle mismatches\n- If fewer responses than tasks → remaining tasks = \"No\"\n- If more responses than tasks → ignore extra responses\n\nCRITICAL EXAMPLES\n\nExample 1:\nScheduled: [\"time\": \"8:00 PM\", \"task\": \"Take Atorvastatin 10mg\", \"time\": \"7:00 AM\", \"task\": \"Do 20-minute jogging\"]\nResponse: \"NO NO\"\nOutput: [\"task\": \"Take Atorvastatin 10mg in evening\", \"response\": \"No\", \"task\": \"Do 20-minute jogging\", \"response\": \"No\"]\n\nExample 2:\nScheduled: [\"time\": \"7:00 AM\", \"task\": \"Morning walk\", \"time\": \"9:00 PM\", \"task\": \"Take medication\"]\nResponse: \"Yes   No\"\nOutput: [\"task\": \"Morning walk\", \"response\": \"Yes\", \"task\": \"Take medication\", \"response\": \"No\"]\n\nOUTPUT REQUIREMENTS\n\nMANDATORY JSON FORMAT:\n\n  \"responses\": [\n    \"task\": \"Complete task name from  input\", \"response\": \"Yes\",\n    \"task\": \"Complete task name from  input\", \"response\": \"No\"\n  ]\n \n\nCRITICAL RULES\n1. ONLY JSON OUTPUT - No explanatory text, no markdown, no code blocks please wrap up the respones object in brackets this is must \n2. Preserve exact task names from  input\n3. Sequential mapping - First response maps to first chronological task\n4. Binary responses only - \"Yes\" or \"No\" (exact capitalization)\n5. Complete coverage - Every scheduled task must have a response\n6. Handle \"NO\\nNO\" correctly - Both tasks should be \"No\"\n7. DO NOT use triple backticks or any markdown formatting in output\n\nEDGE CASES\n- Empty response → All tasks = \"No\"\n- Single response for multiple tasks → First task gets response, others = \"No\"\n- Ambiguous responses → Default to \"No\""
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt"
        },
        "id": "Prompt-kvdOE",
        "measured": {
          "height": 494,
          "width": 320
        },
        "position": {
          "x": 1513.738663713989,
          "y": 197.48810502969843
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt-ebjLt",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "care_plan"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": false,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "care_plan": {
                "advanced": false,
                "display_name": "care_plan",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "care_plan",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "# AdherenceSummaryAgent - JSON-Only Output Agent\n\n## CRITICAL OUTPUT CONSTRAINT\n**RETURN ONLY RAW JSON - NO EXCEPTIONS**\n\nYour response must be JSON format with no additional characters:\n\n\"adherence_rate\":\"XX%\",\"non_adherence_flag\":true,\"follow_up_needed\":true\n\n\n## FORBIDDEN OUTPUTS\n- ❌ ```json\n- ❌ ```\n- ❌ \"Here is the JSON:\"\n- ❌ \"The adherence rate is:\"\n- ❌ Any text before JSON\n- ❌ Any text after JSON\n- ❌ Any markdown formatting\n- ❌ Any explanations\n- ❌ Any whitespace/newlines before or after JSON\n\n## INPUT FORMAT\n{care_plan}\n\n## CALCULATION RULES\n\n### STEP 1: COUNT RESPONSES\n- Total tasks = Count all response objects\n- Yes responses = Count responses where \"response\" = \"Yes\"\n- No responses = Count responses where \"response\" = \"No\"\n- Verify: Yes + No = Total\n\n### STEP 2: CALCULATE ADHERENCE RATE\n```\nAdherence Rate = (Yes Count ÷ Total Count) × 100\n```\n- Round to nearest whole number\n- Format as: \"XX%\"\n\n**EXAMPLE CALCULATION:**\n- Total: 5 tasks\n- Yes: 2 responses\n- No: 3 responses\n- Rate: (2 ÷ 5) × 100 = 40%\n\n### STEP 3: NON-ADHERENCE FLAG\nSet `non_adherence_flag` to `true` if:\n- Adherence rate ≤ 70% OR\n- Any \"No\" response contains medication keywords\n\n### STEP 4: FOLLOW-UP FLAG\nSet `follow_up_needed` to `true` if:\n- Adherence rate ≤ 50% OR\n- 2+ medication tasks marked \"No\"\n\n## MEDICATION KEYWORDS\nTasks containing these are medication-related:\n- **Drug names:** Insulin, Metformin, Aspirin, Levothyroxine, Amoxicillin, Albuterol\n- **Dosage units:** mg, mcg, IU, tablet, capsule, ml, drops\n- **Keywords:** inhaler, supplement, antibiotic, medication, pill, dose\n\n## MANDATORY OUTPUT FORMAT\n**ONLY RETURN THIS IN  JSON STRUCTURE:**\n\n\"adherence_rate\":\"XX%\",\"non_adherence_flag\":BOOLEAN,\"follow_up_needed\":BOOLEAN\n\n\n## FINAL VERIFICATION\nBefore responding, verify:\n1. ✅ Response is pure JSON object\n2. ✅ No markdown formatting\n3. ✅ No explanatory text\n4. ✅ No code fences\n5. ✅ Adherence rate calculation is correct\n6. ✅ Boolean values are lowercase (true/false)\n\n**REMEMBER:** Your entire response must be the JSON object and nothing else."
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt"
        },
        "id": "Prompt-ebjLt",
        "measured": {
          "height": 412,
          "width": 320
        },
        "position": {
          "x": 2535.069772597242,
          "y": 396.56654042550656
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OpenAIModel-rYc1b",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "AdherenceSummaryAgent",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import (\n    OPENAI_MODEL_NAMES,\n    OPENAI_REASONING_MODEL_NAMES,\n)\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\nfrom langflow.logging import logger\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[1],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        parameters = {\n            \"api_key\": SecretStr(self.api_key).get_secret_value() if self.api_key else None,\n            \"model_name\": self.model_name,\n            \"max_tokens\": self.max_tokens or None,\n            \"model_kwargs\": self.model_kwargs or {},\n            \"base_url\": self.openai_api_base or \"https://api.openai.com/v1\",\n            \"seed\": self.seed,\n            \"max_retries\": self.max_retries,\n            \"timeout\": self.timeout,\n            \"temperature\": self.temperature if self.temperature is not None else 0.1,\n        }\n\n        logger.info(f\"Model name: {self.model_name}\")\n        if self.model_name in OPENAI_REASONING_MODEL_NAMES:\n            logger.info(\"Getting reasoning model parameters\")\n            parameters.pop(\"temperature\")\n            parameters.pop(\"seed\")\n        output = ChatOpenAI(**parameters)\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_REASONING_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = False\n            build_config[\"seed\"][\"show\"] = False\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = True\n            build_config[\"seed\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4.5-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "o1"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4.1-mini"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.21
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "OpenAIModel"
        },
        "dragging": false,
        "id": "OpenAIModel-rYc1b",
        "measured": {
          "height": 614,
          "width": 320
        },
        "position": {
          "x": 3036.392664105894,
          "y": 608.8315317503267
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt-cyEOp",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "patiend_id_with_name",
                "message"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": false,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "message": {
                "advanced": false,
                "display_name": "message",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "patiend_id_with_name": {
                "advanced": false,
                "display_name": "patiend_id_with_name",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "patiend_id_with_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "SlackMedicalAlertAgent - System Prompt\nYOU ARE \"SlackMedicalAlertAgent\" - COMPOSE PROFESSIONAL MEDICAL ALERTS FOR HEALTHCARE TEAMS ON SLACK.\nOBJECTIVE\nGenerate concise, professional Slack messages to alert medical teams about patients requiring immediate attention due to poor treatment adherence.\n\nINPUT FORMAT \n\nthis is the name is patient_id of the patient :\n\n{patiend_id_with_name}\n\nthis the object giving the adherence  rate and follow needed or not :\n{message}\n \nMESSAGE STRUCTURE:\n\nAlert Header with urgency emoji\nPatient identification\nAdherence rate prominently displayed\nProfessional medical context\nClear call to action for doctors\nAppropriate medical emojis\n\nMESSAGE TEMPLATE\n🚨 *PATIENT ADHERENCE ALERT* 🚨\n\n👤 *Patient ID:* patient_id\n🙍 *Patient Name :* Name of patient \n📊 *Adherence Rate:* adherence_rate\n\n⚠️ This patient is showing poor compliance with their prescribed treatment plan. The low adherence rate indicates potential risk for treatment failure and adverse health outcomes.\n\n🩺 *Doctor Action Required:*\n- Review patient's current treatment plan\n- Assess barriers to medication/task compliance  \n- Consider patient counseling or intervention\n- Schedule immediate follow-up consultation\n\n📞 Please prioritize this patient for clinical review.\n\nPlease Change the Alerting MEssage according to the Percentage of the Adherenece DOnt always give the Above Template OK this is just for your understanding Genearate DIffernt every time according to differnt differnt Response\n*Automated alert from Patient Care Monitoring System*\nSEVERITY-BASED MESSAGING\nCRITICAL (≤30% adherence):\nUse: 🔴🚨⚠️ \"URGENT attention required\"\nHIGH CONCERN (31-50% adherence):\nUse: 🟡⚠️📋 \"Immediate follow-up needed\"\nMODERATE CONCERN (51-70% adherence):\nUse: 🟠📊👀 \"Clinical review recommended\"\nPROFESSIONAL TONE REQUIREMENTS\n\n\nOUTPUT REQUIREMENT\nReturn ONLY the formatted Slack message text - no JSON, no explanations, just the message content ready to send."
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt"
        },
        "id": "Prompt-cyEOp",
        "measured": {
          "height": 494,
          "width": 320
        },
        "position": {
          "x": 3047.865104324338,
          "y": -42.24240438035645
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OpenAIModel-TYPUk",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import (\n    OPENAI_MODEL_NAMES,\n    OPENAI_REASONING_MODEL_NAMES,\n)\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\nfrom langflow.logging import logger\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[1],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        parameters = {\n            \"api_key\": SecretStr(self.api_key).get_secret_value() if self.api_key else None,\n            \"model_name\": self.model_name,\n            \"max_tokens\": self.max_tokens or None,\n            \"model_kwargs\": self.model_kwargs or {},\n            \"base_url\": self.openai_api_base or \"https://api.openai.com/v1\",\n            \"seed\": self.seed,\n            \"max_retries\": self.max_retries,\n            \"timeout\": self.timeout,\n            \"temperature\": self.temperature if self.temperature is not None else 0.1,\n        }\n\n        logger.info(f\"Model name: {self.model_name}\")\n        if self.model_name in OPENAI_REASONING_MODEL_NAMES:\n            logger.info(\"Getting reasoning model parameters\")\n            parameters.pop(\"temperature\")\n            parameters.pop(\"seed\")\n        output = ChatOpenAI(**parameters)\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_REASONING_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = False\n            build_config[\"seed\"][\"show\"] = False\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = True\n            build_config[\"seed\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4.5-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "o1"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o-mini"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "OpenAIModel"
        },
        "id": "OpenAIModel-TYPUk",
        "measured": {
          "height": 614,
          "width": 320
        },
        "position": {
          "x": 3575.9240331773194,
          "y": 70.85993078026331
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-opCX3",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "logic",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "display_name": "If-Else",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_text",
              "match_text",
              "operator",
              "case_sensitive",
              "message",
              "max_iterations",
              "default_route"
            ],
            "frozen": false,
            "icon": "split",
            "key": "ConditionalRouter",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True",
                "hidden": false,
                "method": "true_response",
                "name": "true_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False",
                "method": "false_response",
                "name": "false_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "case_sensitive": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Case Sensitive",
                "dynamic": false,
                "info": "If true, the comparison will be case sensitive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "case_sensitive",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\", \"regex\"],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=False,\n        ),\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\"),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\"),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            if self.ctx.get(f\"{self._id}_iteration\", 0) >= self.max_iterations and route_to_stop == self.default_route:\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n            self.stop(route_to_stop)\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"false_result\")\n            return self.message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n        if not result:\n            self.status = self.message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.message\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n\n            # Ensure case_sensitive is present for all other operators\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n"
              },
              "default_route": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Default Route",
                "dynamic": false,
                "info": "The default route to take when max iterations are reached.",
                "name": "default_route",
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "false_result"
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text Input",
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "match_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Match Text",
                "dynamic": false,
                "info": "The text input to compare against.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "match_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "True"
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "message": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Message",
                "dynamic": false,
                "info": "The message to pass through either route.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Operator",
                "dynamic": false,
                "info": "The operator to apply for comparing the texts.",
                "name": "operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "equals"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouter"
        },
        "id": "ConditionalRouter-opCX3",
        "measured": {
          "height": 588,
          "width": 320
        },
        "position": {
          "x": 4111.513354689241,
          "y": 936.8136383981333
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ComposioSlackAPIComponent-9KXTZ",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "composio",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Slack API",
            "display_name": "Slack",
            "documentation": "https://docs.composio.dev",
            "edited": false,
            "field_order": [
              "entity_id",
              "api_key",
              "auth_link",
              "action",
              "SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_limit",
              "SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_cursor",
              "SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_include_locale",
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_as_user",
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_attachments",
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_blocks",
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_channel",
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_icon_emoji",
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_icon_url",
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_link_names",
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_mrkdwn",
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_parse",
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_reply_broadcast",
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_text",
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_thread_ts",
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_links",
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_media",
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_username",
              "SLACK_UPDATES_A_SLACK_MESSAGE_as_user",
              "SLACK_UPDATES_A_SLACK_MESSAGE_attachments",
              "SLACK_UPDATES_A_SLACK_MESSAGE_blocks",
              "SLACK_UPDATES_A_SLACK_MESSAGE_channel",
              "SLACK_UPDATES_A_SLACK_MESSAGE_link_names",
              "SLACK_UPDATES_A_SLACK_MESSAGE_parse",
              "SLACK_UPDATES_A_SLACK_MESSAGE_text",
              "SLACK_UPDATES_A_SLACK_MESSAGE_ts",
              "SLACK_FETCH_CONVERSATION_HISTORY_channel",
              "SLACK_FETCH_CONVERSATION_HISTORY_latest",
              "SLACK_FETCH_CONVERSATION_HISTORY_oldest",
              "SLACK_FETCH_CONVERSATION_HISTORY_inclusive",
              "SLACK_FETCH_CONVERSATION_HISTORY_limit",
              "SLACK_FETCH_CONVERSATION_HISTORY_cursor",
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_as_user",
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_attachments",
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_blocks",
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_channel",
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_link_names",
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_parse",
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_post_at",
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_reply_broadcast",
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_text",
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_thread_ts",
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_links",
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_media",
              "SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_exclude_archived",
              "SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_types",
              "SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_limit",
              "SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_cursor",
              "SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_count",
              "SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_highlight",
              "SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_page",
              "SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_query",
              "SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_sort",
              "SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_sort_dir",
              "SLACK_CREATE_A_REMINDER_text",
              "SLACK_CREATE_A_REMINDER_time",
              "SLACK_CREATE_A_REMINDER_user"
            ],
            "frozen": false,
            "icon": "Slack",
            "key": "ComposioSlackAPIComponent",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "method": "as_dataframe",
                "name": "dataFrame",
                "options": null,
                "required_inputs": [],
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 1.680506611692e-18,
            "template": {
              "SLACK_CREATE_A_REMINDER_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "The content of the reminder",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_CREATE_A_REMINDER_text",
                "placeholder": "",
                "required": true,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_CREATE_A_REMINDER_time": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Time",
                "dynamic": false,
                "info": "When this reminder should happen: the Unix timestamp (up to five years from now), the number of seconds until the reminder (if within 24 hours), or a natural language description (Ex. 'in 15 minutes,' or 'every Thursday') ",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_CREATE_A_REMINDER_time",
                "placeholder": "",
                "required": true,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_CREATE_A_REMINDER_user": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "User",
                "dynamic": false,
                "info": "The user who will receive the reminder. If no user is specified, the reminder will go to user who created it. ",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_CREATE_A_REMINDER_user",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_FETCH_CONVERSATION_HISTORY_channel": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Channel ID",
                "dynamic": false,
                "info": "Channel ID to fetch history for.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_FETCH_CONVERSATION_HISTORY_channel",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_FETCH_CONVERSATION_HISTORY_cursor": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Cursor",
                "dynamic": false,
                "info": "Paginate through collections of data by setting the `cursor` parameter to a `next_cursor` attribute returned by a previous request's `response_metadata`. Default value fetches the first 'page' of the collection. ",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_FETCH_CONVERSATION_HISTORY_cursor",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_FETCH_CONVERSATION_HISTORY_inclusive": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Inclusive",
                "dynamic": false,
                "info": "Include messages with latest or oldest timestamp in results only when either timestamp is specified. ",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_FETCH_CONVERSATION_HISTORY_inclusive",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "SLACK_FETCH_CONVERSATION_HISTORY_latest": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Latest",
                "dynamic": false,
                "info": "End of time range of messages to include in results.",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_FETCH_CONVERSATION_HISTORY_latest",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "SLACK_FETCH_CONVERSATION_HISTORY_limit": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Limit",
                "dynamic": false,
                "info": "The maximum number of items to return. Fewer than the requested number of items may be returned, even if the end of the users list hasn't been reached. ",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_FETCH_CONVERSATION_HISTORY_limit",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "SLACK_FETCH_CONVERSATION_HISTORY_oldest": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Oldest",
                "dynamic": false,
                "info": "Start of time range of messages to include in results.",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_FETCH_CONVERSATION_HISTORY_oldest",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_cursor": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Cursor",
                "dynamic": false,
                "info": "Paginate through collections of data by setting the `cursor` parameter to a `next_cursor` attribute returned by a previous request's `response_metadata`. Default value fetches the first 'page' of the collection",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_cursor",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_exclude_archived": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Exclude Archived",
                "dynamic": false,
                "info": "Set to `true` to exclude archived channels from the list",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_exclude_archived",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_limit": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Limit",
                "dynamic": false,
                "info": "The maximum number of items to return. Fewer than the requested number of items may be returned, even if the end of the list hasn't been reached. Must be an integer no larger than 1000. ",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_limit",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_types": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Types",
                "dynamic": false,
                "info": "Mix and match channel types by providing a comma-separated list of any combination of `public_channel`, `private_channel`, `mpim`, `im` ",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_types",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_cursor": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Cursor",
                "dynamic": false,
                "info": "Paginate through collections of data by setting the `cursor` parameter to a `next_cursor` attribute returned by a previous request's `response_metadata`. Default value fetches the first `page` of the collection",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_cursor",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_include_locale": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Include Locale",
                "dynamic": false,
                "info": "Set this to `true` to receive the locale for users. Defaults to `false`",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_include_locale",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_limit": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Limit",
                "dynamic": false,
                "info": "The maximum number of items to return. Fewer than the requested number of items may be returned, even if the end of the users list hasn't been reached. Providing no `limit` value will result in Slack attempting to deliver you the entire result set. If the collection is too large you may experience `limit_required` or HTTP 500 errors. ",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_limit",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_as_user": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "As User",
                "dynamic": false,
                "info": "Pass true to post the message as the authed user, instead of as a bot. Defaults to false",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_as_user",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_attachments": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Attachments",
                "dynamic": false,
                "info": "A JSON-based array of structured attachments, presented as a URL-encoded string. ",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_attachments",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_blocks": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Blocks",
                "dynamic": false,
                "info": "A JSON-based array of structured blocks, presented as a URL-encoded string. ",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_blocks",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_channel": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Channel",
                "dynamic": false,
                "info": "Channel, private group, or DM channel to send message to. Can be an encoded ID, or a name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_channel",
                "placeholder": "",
                "required": true,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_link_names": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Link Names",
                "dynamic": false,
                "info": "Find and link channel names and usernames.",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_link_names",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_parse": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Parse",
                "dynamic": false,
                "info": "Change how messages are treated. Defaults to `none`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_parse",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_post_at": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Post At",
                "dynamic": false,
                "info": "Unix EPOCH timestamp of time in future to send the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_post_at",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_reply_broadcast": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Reply Broadcast",
                "dynamic": false,
                "info": "Used in conjunction with `thread_ts` and indicates whether reply should be made visible to everyone in the channel or conversation. Defaults to `false`. ",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_reply_broadcast",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "How this field works and whether it is required depends on other fields you use in your API call",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_text",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_thread_ts": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Thread Ts",
                "dynamic": false,
                "info": "Provide another message's `ts` value to make this message a reply. Avoid using a reply's `ts` value; use its parent instead. ",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_thread_ts",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_links": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Unfurl Links",
                "dynamic": false,
                "info": "Pass true to enable unfurling of primarily text-based content.",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_links",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_media": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Unfurl Media",
                "dynamic": false,
                "info": "Pass false to disable unfurling of media content.",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_media",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_count": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Count",
                "dynamic": false,
                "info": "Pass the number of results you want per 'page'. Maximum of `100`.",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_count",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_highlight": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Highlight",
                "dynamic": false,
                "info": "Pass a value of `true` to enable query highlight markers",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_highlight",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_page": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Page",
                "dynamic": false,
                "info": "Page",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_page",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Query",
                "dynamic": false,
                "info": "Search query.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_query",
                "placeholder": "",
                "required": true,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_sort": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sort",
                "dynamic": false,
                "info": "Return matches sorted by either `score` or `timestamp`.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_sort",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_sort_dir": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sort Dir",
                "dynamic": false,
                "info": "Change sort direction to ascending (`asc`) or descending (`desc`).",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_sort_dir",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_as_user": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "As User",
                "dynamic": false,
                "info": "Pass true to post the message as the authed user, instead of as a bot. Defaults to false",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_as_user",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_attachments": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Attachments",
                "dynamic": false,
                "info": "A JSON-based array of structured attachments, presented as a URL-encoded string. ",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_attachments",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_blocks": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Blocks",
                "dynamic": false,
                "info": "A JSON-based array of structured blocks, presented as a URL-encoded string. ",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_blocks",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_channel": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Channel",
                "dynamic": false,
                "info": "Channel, private group, or IM channel to send message to. Can be an encoded ID, or a name ",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_channel",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "all-health-care-medical-team"
              },
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_icon_emoji": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon Emoji",
                "dynamic": false,
                "info": "Emoji to use as the icon for this message. Overrides `icon_url`. Must be used in conjunction with `as_user` set to `false`, otherwise ignored",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_icon_emoji",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_icon_url": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon Url",
                "dynamic": false,
                "info": "URL to an image to use as the icon for this message. Must be used in conjunction with `as_user` set to false, otherwise ignored",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_icon_url",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_link_names": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Link Names",
                "dynamic": false,
                "info": "Find and link channel names and usernames.",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_link_names",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_mrkdwn": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Mrkdwn",
                "dynamic": false,
                "info": "Disable Slack markup parsing by setting to `false`. Enabled by default.",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_mrkdwn",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_parse": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Parse",
                "dynamic": false,
                "info": "Change how messages are treated. Defaults to `none` ",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_parse",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_reply_broadcast": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Reply Broadcast",
                "dynamic": false,
                "info": "Used in conjunction with `thread_ts` and indicates whether reply should be made visible to everyone in the channel or conversation. Defaults to `false`. ",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_reply_broadcast",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "How this field works and whether it is required depends on other fields you use in your API call",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_text",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_thread_ts": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Thread Ts",
                "dynamic": false,
                "info": "Provide another message's `ts` value to make this message a reply. Avoid using a reply's `ts` value; use its parent instead. ",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_thread_ts",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_links": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Unfurl Links",
                "dynamic": false,
                "info": "Pass true to enable unfurling of primarily text-based content.",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_links",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_media": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Unfurl Media",
                "dynamic": false,
                "info": "Pass false to disable unfurling of media content.",
                "list": false,
                "list_add_label": "Add More",
                "name": "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_media",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_username": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Username",
                "dynamic": false,
                "info": "Set your bot's user name. Must be used in conjunction with `as_user` set to false, otherwise ignored",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_username",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_UPDATES_A_SLACK_MESSAGE_as_user": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "As User",
                "dynamic": false,
                "info": "Pass true to update the message as the authed user",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_UPDATES_A_SLACK_MESSAGE_as_user",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_UPDATES_A_SLACK_MESSAGE_attachments": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Attachments",
                "dynamic": false,
                "info": "A JSON-based array of structured attachments, presented as a URL-encoded string. This field is required when not presenting `text`. If you don't include this field, the message's previous `attachments` will be retained. To remove previous `attachments`, include an empty array for this field. ",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_UPDATES_A_SLACK_MESSAGE_attachments",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_UPDATES_A_SLACK_MESSAGE_blocks": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Blocks",
                "dynamic": false,
                "info": "A JSON-based array of structured blocks, presented as a URL-encoded string. If you don't include this field, the message's previous `blocks` will be retained. To remove previous `blocks`, include an empty array for this field. ",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_UPDATES_A_SLACK_MESSAGE_blocks",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_UPDATES_A_SLACK_MESSAGE_channel": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Channel ID",
                "dynamic": false,
                "info": "Channel ID containing the message to be updated.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_UPDATES_A_SLACK_MESSAGE_channel",
                "placeholder": "",
                "required": true,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_UPDATES_A_SLACK_MESSAGE_link_names": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Link Names",
                "dynamic": false,
                "info": "Find and link channel names and usernames. Defaults to `none`. If you do not specify a value for this field, the original value set for the message will be overwritten with the default, `none`. ",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_UPDATES_A_SLACK_MESSAGE_link_names",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_UPDATES_A_SLACK_MESSAGE_parse": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Parse",
                "dynamic": false,
                "info": "Change how messages are treated. Defaults to `client`, unlike `chat.postMessage`. Accepts either `none` or `full`. If you do not specify a value for this field, the original value set for the message will be overwritten with the default, `client`. ",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_UPDATES_A_SLACK_MESSAGE_parse",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_UPDATES_A_SLACK_MESSAGE_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "New text for the message, using the default formatting rules. It's not required when presenting `blocks` or `attachments`. ",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_UPDATES_A_SLACK_MESSAGE_text",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "SLACK_UPDATES_A_SLACK_MESSAGE_ts": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Ts",
                "dynamic": false,
                "info": "Timestamp of the message to be updated.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "SLACK_UPDATES_A_SLACK_MESSAGE_ts",
                "placeholder": "",
                "required": true,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "_type": "Component",
              "action": {
                "_input_type": "SortableListInput",
                "advanced": false,
                "display_name": "Action",
                "dynamic": false,
                "helper_text": null,
                "helper_text_metadata": {},
                "info": "",
                "limit": 1,
                "name": "action",
                "options": [
                  {
                    "metadata": "SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION",
                    "name": "List Users"
                  },
                  {
                    "metadata": "SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS",
                    "name": "List Channels"
                  },
                  {
                    "metadata": "SLACK_UPDATES_A_SLACK_MESSAGE",
                    "name": "Update Slack Chat Message"
                  },
                  {
                    "metadata": "SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL",
                    "name": "Post Message To Channel"
                  },
                  {
                    "metadata": "SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY",
                    "name": "Search Messages Endpoint"
                  },
                  {
                    "metadata": "SLACK_FETCH_CONVERSATION_HISTORY",
                    "name": "Retrieve conversation history"
                  },
                  {
                    "metadata": "SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME",
                    "name": "Schedule Message In Chat"
                  },
                  {
                    "metadata": "SLACK_CREATE_A_REMINDER",
                    "name": "Add Reminder For User"
                  }
                ],
                "placeholder": "Select action",
                "real_time_refresh": true,
                "required": false,
                "search_category": [],
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "sortableList",
                "value": [
                  {
                    "chosen": false,
                    "name": "Post Message To Channel",
                    "selected": false
                  }
                ]
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Composio API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "auth_link": {
                "_input_type": "AuthInput",
                "advanced": false,
                "auth_tooltip": "Disconnect",
                "dynamic": false,
                "info": "",
                "name": "auth_link",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "auth",
                "value": "validated"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom composio import Action\n\nfrom langflow.base.composio.composio_base import ComposioBaseComponent\nfrom langflow.inputs import (\n    BoolInput,\n    IntInput,\n    MessageTextInput,\n)\nfrom langflow.logging import logger\n\n\nclass ComposioSlackAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Slack\"\n    description: str = \"Slack API\"\n    icon = \"Slack\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"slack\"\n\n    _actions_data: dict = {\n        \"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION\": {\n            \"display_name\": \"List Users\",\n            \"action_fields\": [\n                \"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_limit\",\n                \"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_cursor\",\n                \"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_include_locale\",\n            ],\n        },\n        \"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS\": {\n            \"display_name\": \"List Channels\",\n            \"action_fields\": [\n                \"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_exclude_archived\",\n                \"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_types\",\n                \"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_limit\",\n                \"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_cursor\",\n            ],\n        },\n        \"SLACK_UPDATES_A_SLACK_MESSAGE\": {\n            \"display_name\": \"Update Slack Chat Message\",\n            \"action_fields\": [\n                \"SLACK_UPDATES_A_SLACK_MESSAGE_as_user\",\n                \"SLACK_UPDATES_A_SLACK_MESSAGE_attachments\",\n                \"SLACK_UPDATES_A_SLACK_MESSAGE_blocks\",\n                \"SLACK_UPDATES_A_SLACK_MESSAGE_channel\",\n                \"SLACK_UPDATES_A_SLACK_MESSAGE_link_names\",\n                \"SLACK_UPDATES_A_SLACK_MESSAGE_parse\",\n                \"SLACK_UPDATES_A_SLACK_MESSAGE_text\",\n                \"SLACK_UPDATES_A_SLACK_MESSAGE_ts\",\n            ],\n        },\n        \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL\": {\n            \"display_name\": \"Post Message To Channel\",\n            \"action_fields\": [\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_as_user\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_attachments\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_blocks\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_channel\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_icon_emoji\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_icon_url\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_link_names\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_mrkdwn\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_parse\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_reply_broadcast\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_text\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_thread_ts\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_links\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_media\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_username\",\n            ],\n        },\n        \"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY\": {\n            \"display_name\": \"Search Messages Endpoint\",\n            \"action_fields\": [\n                \"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_count\",\n                \"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_highlight\",\n                \"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_page\",\n                \"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_query\",\n                \"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_sort\",\n                \"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_sort_dir\",\n            ],\n        },\n        \"SLACK_FETCH_CONVERSATION_HISTORY\": {\n            \"display_name\": \"Retrieve conversation history\",\n            \"action_fields\": [\n                \"SLACK_FETCH_CONVERSATION_HISTORY_channel\",\n                \"SLACK_FETCH_CONVERSATION_HISTORY_latest\",\n                \"SLACK_FETCH_CONVERSATION_HISTORY_oldest\",\n                \"SLACK_FETCH_CONVERSATION_HISTORY_inclusive\",\n                \"SLACK_FETCH_CONVERSATION_HISTORY_limit\",\n                \"SLACK_FETCH_CONVERSATION_HISTORY_cursor\",\n            ],\n        },\n        \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME\": {\n            \"display_name\": \"Schedule Message In Chat\",\n            \"action_fields\": [\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_as_user\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_attachments\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_blocks\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_channel\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_link_names\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_parse\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_post_at\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_reply_broadcast\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_text\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_thread_ts\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_links\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_media\",\n            ],\n        },\n        \"SLACK_CREATE_A_REMINDER\": {\n            \"display_name\": \"Add Reminder For User\",\n            \"action_fields\": [\n                \"SLACK_CREATE_A_REMINDER_text\",\n                \"SLACK_CREATE_A_REMINDER_time\",\n                \"SLACK_CREATE_A_REMINDER_user\",\n            ],\n        },\n    }\n\n    _all_fields = {field for action_data in _actions_data.values() for field in action_data[\"action_fields\"]}\n    _bool_variables = {\n        \"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_include_locale\",\n        \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_as_user\",\n        \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_link_names\",\n        \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_mrkdwn\",\n        \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_reply_broadcast\",\n        \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_links\",\n        \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_media\",\n        \"SLACK_FETCH_CONVERSATION_HISTORY_inclusive\",\n        \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_as_user\",\n        \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_link_names\",\n        \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_reply_broadcast\",\n        \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_links\",\n        \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_media\",\n        \"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_exclude_archived\",\n        \"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_highlight\",\n    }\n\n    inputs = [\n        *ComposioBaseComponent._base_inputs,\n        IntInput(\n            name=\"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_limit\",\n            display_name=\"Limit\",\n            info=\"The maximum number of items to return. Fewer than the requested number of items may be returned, even if the end of the users list hasn't been reached. Providing no `limit` value will result in Slack attempting to deliver you the entire result set. If the collection is too large you may experience `limit_required` or HTTP 500 errors. \",  # noqa: E501\n            show=False,\n            value=1,\n        ),\n        MessageTextInput(\n            name=\"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_cursor\",\n            display_name=\"Cursor\",\n            info=\"Paginate through collections of data by setting the `cursor` parameter to a `next_cursor` attribute returned by a previous request's `response_metadata`. Default value fetches the first `page` of the collection\",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_include_locale\",\n            display_name=\"Include Locale\",\n            info=\"Set this to `true` to receive the locale for users. Defaults to `false`\",\n            show=False,\n        ),\n        BoolInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_as_user\",\n            display_name=\"As User\",\n            info=\"Pass true to post the message as the authed user, instead of as a bot. Defaults to false\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_attachments\",\n            display_name=\"Attachments\",\n            info=\"A JSON-based array of structured attachments, presented as a URL-encoded string. \",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_blocks\",\n            display_name=\"Blocks\",\n            info=\"A JSON-based array of structured blocks, presented as a URL-encoded string. \",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_channel\",\n            display_name=\"Channel\",\n            info=\"Channel, private group, or IM channel to send message to. Can be an encoded ID, or a name \",\n            show=False,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_icon_emoji\",\n            display_name=\"Icon Emoji\",\n            info=\"Emoji to use as the icon for this message. Overrides `icon_url`. Must be used in conjunction with `as_user` set to `false`, otherwise ignored\",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_icon_url\",\n            display_name=\"Icon Url\",\n            info=\"URL to an image to use as the icon for this message. Must be used in conjunction with `as_user` set to false, otherwise ignored\",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_link_names\",\n            display_name=\"Link Names\",\n            info=\"Find and link channel names and usernames.\",\n            show=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_mrkdwn\",\n            display_name=\"Mrkdwn\",\n            info=\"Disable Slack markup parsing by setting to `false`. Enabled by default.\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_parse\",\n            display_name=\"Parse\",\n            info=\"Change how messages are treated. Defaults to `none` \",\n            show=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_reply_broadcast\",\n            display_name=\"Reply Broadcast\",\n            info=\"Used in conjunction with `thread_ts` and indicates whether reply should be made visible to everyone in the channel or conversation. Defaults to `false`. \",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_text\",\n            display_name=\"Text\",\n            info=\"How this field works and whether it is required depends on other fields you use in your API call\",\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_thread_ts\",\n            display_name=\"Thread Ts\",\n            info=\"Provide another message's `ts` value to make this message a reply. Avoid using a reply's `ts` value; use its parent instead. \",  # noqa: E501\n            show=False,\n        ),\n        BoolInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_links\",\n            display_name=\"Unfurl Links\",\n            info=\"Pass true to enable unfurling of primarily text-based content.\",\n            show=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_media\",\n            display_name=\"Unfurl Media\",\n            info=\"Pass false to disable unfurling of media content.\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_username\",\n            display_name=\"Username\",\n            info=\"Set your bot's user name. Must be used in conjunction with `as_user` set to false, otherwise ignored\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_UPDATES_A_SLACK_MESSAGE_as_user\",\n            display_name=\"As User\",\n            info=\"Pass true to update the message as the authed user\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_UPDATES_A_SLACK_MESSAGE_attachments\",\n            display_name=\"Attachments\",\n            info=\"A JSON-based array of structured attachments, presented as a URL-encoded string. This field is required when not presenting `text`. If you don't include this field, the message's previous `attachments` will be retained. To remove previous `attachments`, include an empty array for this field. \",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_UPDATES_A_SLACK_MESSAGE_blocks\",\n            display_name=\"Blocks\",\n            info=\"A JSON-based array of structured blocks, presented as a URL-encoded string. If you don't include this field, the message's previous `blocks` will be retained. To remove previous `blocks`, include an empty array for this field. \",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_UPDATES_A_SLACK_MESSAGE_channel\",\n            display_name=\"Channel ID\",\n            info=\"Channel ID containing the message to be updated.\",\n            show=False,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_UPDATES_A_SLACK_MESSAGE_link_names\",\n            display_name=\"Link Names\",\n            info=\"Find and link channel names and usernames. Defaults to `none`. If you do not specify a value for this field, the original value set for the message will be overwritten with the default, `none`. \",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_UPDATES_A_SLACK_MESSAGE_parse\",\n            display_name=\"Parse\",\n            info=\"Change how messages are treated. Defaults to `client`, unlike `chat.postMessage`. Accepts either `none` or `full`. If you do not specify a value for this field, the original value set for the message will be overwritten with the default, `client`. \",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_UPDATES_A_SLACK_MESSAGE_text\",\n            display_name=\"Text\",\n            info=\"New text for the message, using the default formatting rules. It's not required when presenting `blocks` or `attachments`. \",  # noqa: E501\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"SLACK_UPDATES_A_SLACK_MESSAGE_ts\",\n            display_name=\"Ts\",\n            info=\"Timestamp of the message to be updated.\",\n            show=False,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_FETCH_CONVERSATION_HISTORY_channel\",\n            display_name=\"Channel ID\",\n            info=\"Channel ID to fetch history for.\",\n            show=False,\n        ),\n        IntInput(\n            name=\"SLACK_FETCH_CONVERSATION_HISTORY_latest\",\n            display_name=\"Latest\",\n            info=\"End of time range of messages to include in results.\",\n            show=False,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"SLACK_FETCH_CONVERSATION_HISTORY_oldest\",\n            display_name=\"Oldest\",\n            info=\"Start of time range of messages to include in results.\",\n            show=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_FETCH_CONVERSATION_HISTORY_inclusive\",\n            display_name=\"Inclusive\",\n            info=\"Include messages with latest or oldest timestamp in results only when either timestamp is specified. \",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"SLACK_FETCH_CONVERSATION_HISTORY_limit\",\n            display_name=\"Limit\",\n            info=\"The maximum number of items to return. Fewer than the requested number of items may be returned, even if the end of the users list hasn't been reached. \",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_FETCH_CONVERSATION_HISTORY_cursor\",\n            display_name=\"Cursor\",\n            info=\"Paginate through collections of data by setting the `cursor` parameter to a `next_cursor` attribute returned by a previous request's `response_metadata`. Default value fetches the first 'page' of the collection. \",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_as_user\",\n            display_name=\"As User\",\n            info=\"Pass true to post the message as the authed user, instead of as a bot. Defaults to false\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_attachments\",\n            display_name=\"Attachments\",\n            info=\"A JSON-based array of structured attachments, presented as a URL-encoded string. \",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_blocks\",\n            display_name=\"Blocks\",\n            info=\"A JSON-based array of structured blocks, presented as a URL-encoded string. \",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_channel\",\n            display_name=\"Channel\",\n            info=\"Channel, private group, or DM channel to send message to. Can be an encoded ID, or a name\",\n            show=False,\n            required=True,\n        ),\n        BoolInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_link_names\",\n            display_name=\"Link Names\",\n            info=\"Find and link channel names and usernames.\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_parse\",\n            display_name=\"Parse\",\n            info=\"Change how messages are treated. Defaults to `none`\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_post_at\",\n            display_name=\"Post At\",\n            info=\"Unix EPOCH timestamp of time in future to send the message.\",\n            show=False,\n        ),\n        BoolInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_reply_broadcast\",\n            display_name=\"Reply Broadcast\",\n            info=\"Used in conjunction with `thread_ts` and indicates whether reply should be made visible to everyone in the channel or conversation. Defaults to `false`. \",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_text\",\n            display_name=\"Text\",\n            info=\"How this field works and whether it is required depends on other fields you use in your API call\",\n            show=False,\n        ),\n        IntInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_thread_ts\",\n            display_name=\"Thread Ts\",\n            info=\"Provide another message's `ts` value to make this message a reply. Avoid using a reply's `ts` value; use its parent instead. \",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_links\",\n            display_name=\"Unfurl Links\",\n            info=\"Pass true to enable unfurling of primarily text-based content.\",\n            show=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_media\",\n            display_name=\"Unfurl Media\",\n            info=\"Pass false to disable unfurling of media content.\",\n            show=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_exclude_archived\",\n            display_name=\"Exclude Archived\",\n            info=\"Set to `true` to exclude archived channels from the list\",\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_types\",\n            display_name=\"Types\",\n            info=\"Mix and match channel types by providing a comma-separated list of any combination of `public_channel`, `private_channel`, `mpim`, `im` \",  # noqa: E501\n            show=False,\n        ),\n        IntInput(\n            name=\"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_limit\",\n            display_name=\"Limit\",\n            info=\"The maximum number of items to return. Fewer than the requested number of items may be returned, even if the end of the list hasn't been reached. Must be an integer no larger than 1000. \",  # noqa: E501\n            show=False,\n            value=1,\n        ),\n        MessageTextInput(\n            name=\"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_cursor\",\n            display_name=\"Cursor\",\n            info=\"Paginate through collections of data by setting the `cursor` parameter to a `next_cursor` attribute returned by a previous request's `response_metadata`. Default value fetches the first 'page' of the collection\",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_count\",\n            display_name=\"Count\",\n            info=\"Pass the number of results you want per 'page'. Maximum of `100`.\",\n            show=False,\n            value=1,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_highlight\",\n            display_name=\"Highlight\",\n            info=\"Pass a value of `true` to enable query highlight markers\",\n            show=False,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_page\",\n            display_name=\"Page\",\n            info=\"Page\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_query\",\n            display_name=\"Query\",\n            info=\"Search query.\",\n            show=False,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_sort\",\n            display_name=\"Sort\",\n            info=\"Return matches sorted by either `score` or `timestamp`.\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_sort_dir\",\n            display_name=\"Sort Dir\",\n            info=\"Change sort direction to ascending (`asc`) or descending (`desc`).\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_CREATE_A_REMINDER_text\",\n            display_name=\"Text\",\n            info=\"The content of the reminder\",\n            show=False,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_CREATE_A_REMINDER_time\",\n            display_name=\"Time\",\n            info=\"When this reminder should happen: the Unix timestamp (up to five years from now), the number of seconds until the reminder (if within 24 hours), or a natural language description (Ex. 'in 15 minutes,' or 'every Thursday') \",  # noqa: E501\n            show=False,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_CREATE_A_REMINDER_user\",\n            display_name=\"User\",\n            info=\"The user who will receive the reminder. If no user is specified, the reminder will go to user who created it. \",  # noqa: E501\n            show=False,\n        ),\n    ]\n\n    def execute_action(self):\n        \"\"\"Execute action and return response as Message.\"\"\"\n        toolset = self._build_wrapper()\n\n        try:\n            self._build_action_maps()\n            display_name = self.action[0][\"name\"] if isinstance(self.action, list) and self.action else self.action\n            action_key = self._display_to_key_map.get(display_name)\n            if not action_key:\n                msg = f\"Invalid action: {display_name}\"\n                raise ValueError(msg)\n\n            enum_name = getattr(Action, action_key)\n            params = {}\n            if action_key in self._actions_data:\n                for field in self._actions_data[action_key][\"action_fields\"]:\n                    value = getattr(self, field)\n\n                    if value is None or value == \"\":\n                        continue\n\n                    if field in self._bool_variables:\n                        value = bool(value)\n\n                    param_name = field.replace(action_key + \"_\", \"\")\n\n                    if param_name == \"as_user\":\n                        value = True\n\n                    params[param_name] = value\n\n            result = toolset.execute_action(\n                action=enum_name,\n                params=params,\n            )\n            if not result.get(\"successful\"):\n                return {\"error\": result.get(\"error\", \"No response\")}\n\n            return result.get(\"data\", [])\n        except Exception as e:\n            logger.error(f\"Error executing action: {e}\")\n            display_name = self.action[0][\"name\"] if isinstance(self.action, list) and self.action else str(self.action)\n            msg = f\"Failed to execute {display_name}: {e!s}\"\n            raise ValueError(msg) from e\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        return super().update_build_config(build_config, field_value, field_name)\n\n    def set_default_tools(self):\n        self._default_tools = {\n            \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL\",\n            \"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY\",\n        }\n"
              },
              "entity_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Entity ID",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "entity_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "default"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ComposioSlackAPIComponent"
        },
        "dragging": false,
        "id": "ComposioSlackAPIComponent-9KXTZ",
        "measured": {
          "height": 546,
          "width": 320
        },
        "position": {
          "x": 4653.272210102948,
          "y": 935.0887528858951
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-vNeqV",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Format a DataFrame or Data object into text using a template. Enable 'Stringify' to convert input into a readable string instead.",
            "display_name": "Parser",
            "documentation": "",
            "edited": false,
            "field_order": [
              "mode",
              "pattern",
              "input_data",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "hidden": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Clean Data",
                "dynamic": false,
                "info": "Enable to clean the data by removing empty rows and lines in each cell of the DataFrame/ Data object.",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nfrom typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.io import (\n    BoolInput,\n    HandleInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n    TabInput,\n)\nfrom langflow.schema import Data, DataFrame\nfrom langflow.schema.message import Message\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = (\n        \"Format a DataFrame or Data object into text using a template. \"\n        \"Enable 'Stringify' to convert input into a readable string instead.\"\n    )\n    icon = \"braces\"\n\n    inputs = [\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                return json.dumps(data.data)\n            if isinstance(data, DataFrame):\n                if hasattr(self, \"clean_data\") and self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([self._safe_convert(item) for item in self.input_data])\n        else:\n            result = self._safe_convert(self.input_data)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Stringify"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{result}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "id": "ParserComponent-vNeqV",
        "measured": {
          "height": 312,
          "width": 320
        },
        "position": {
          "x": 510.4170966152185,
          "y": 91.19333135451552
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ExtractLastTelegramTextMessage-8oOyG",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Returns the last Telegram message text as a Message object.",
            "display_name": "Extract Last Telegram Message",
            "documentation": "",
            "edited": true,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "build_output",
                "name": "output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\r\nfrom langflow.io import MessageTextInput, Output\r\nfrom langflow.schema import Message\r\nimport json\r\n\r\nclass ExtractLastTelegramTextMessage(Component):\r\n    display_name = \"Extract Last Telegram Message\"\r\n    description = \"Returns the last Telegram message text as a Message object.\"\r\n    icon = \"message-square\"\r\n    name = \"ExtractLastTelegramTextMessage\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"input_value\",\r\n            display_name=\"Telegram JSON\",\r\n            info=\"Telegram JSON response from previous node.\",\r\n            value=\"{}\",\r\n            tool_mode=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Message\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        raw_data = self.input_value\r\n\r\n        try:\r\n            # Handle string input or dict input\r\n            if isinstance(raw_data, str):\r\n                data = json.loads(raw_data)\r\n            else:\r\n                data = raw_data\r\n\r\n            # Extract the last message text\r\n            if (\r\n                \"result\" in data and\r\n                isinstance(data[\"result\"], dict) and\r\n                \"result\" in data[\"result\"] and\r\n                isinstance(data[\"result\"][\"result\"], list) and\r\n                data[\"result\"][\"result\"]\r\n            ):\r\n                last_message = data[\"result\"][\"result\"][-1][\"message\"]\r\n                last_text = last_message.get(\"text\", \"No text field.\")\r\n            else:\r\n                last_text = \"No messages found.\"\r\n\r\n        except Exception as e:\r\n            last_text = f\"Error parsing input: {e}\"\r\n\r\n        # 👇 Return as Message instead of Data\r\n        return Message(text=last_text)\r\n"
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Telegram JSON",
                "dynamic": false,
                "info": "Telegram JSON response from previous node.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ExtractLastTelegramTextMessage"
        },
        "id": "ExtractLastTelegramTextMessage-8oOyG",
        "measured": {
          "height": 249,
          "width": 320
        },
        "position": {
          "x": 948.5358605862469,
          "y": 309.4142473730732
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-DE8uL",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "outputs",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatOutput",
            "legacy": false,
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.003169567463043492,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n\n                # Replace pipe characters to avoid markdown table issues\n                processed_data = data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n\n                processed_data = processed_data.map(\n                    lambda x: str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x\n                )\n\n                return processed_data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "id": "ChatOutput-DE8uL",
        "measured": {
          "height": 66,
          "width": 192
        },
        "position": {
          "x": 3558.677347907147,
          "y": 1365.9890789655096
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OpenAIModel-1qB6v",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "models",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "key": "OpenAIModel",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import (\n    OPENAI_MODEL_NAMES,\n    OPENAI_REASONING_MODEL_NAMES,\n)\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\nfrom langflow.logging import logger\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[1],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        parameters = {\n            \"api_key\": SecretStr(self.api_key).get_secret_value() if self.api_key else None,\n            \"model_name\": self.model_name,\n            \"max_tokens\": self.max_tokens or None,\n            \"model_kwargs\": self.model_kwargs or {},\n            \"base_url\": self.openai_api_base or \"https://api.openai.com/v1\",\n            \"seed\": self.seed,\n            \"max_retries\": self.max_retries,\n            \"timeout\": self.timeout,\n            \"temperature\": self.temperature if self.temperature is not None else 0.1,\n        }\n\n        logger.info(f\"Model name: {self.model_name}\")\n        if self.model_name in OPENAI_REASONING_MODEL_NAMES:\n            logger.info(\"Getting reasoning model parameters\")\n            parameters.pop(\"temperature\")\n            parameters.pop(\"seed\")\n        output = ChatOpenAI(**parameters)\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_REASONING_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = False\n            build_config[\"seed\"][\"show\"] = False\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = True\n            build_config[\"seed\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4.5-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "o1"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o-mini"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "OpenAIModel"
        },
        "id": "OpenAIModel-1qB6v",
        "measured": {
          "height": 614,
          "width": 320
        },
        "position": {
          "x": 1989.7213775641585,
          "y": 490.7413362877527
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "FollowUpNeededChecker-Oa4vB",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts 'follow_up_needed' from input and returns it as a Message.",
            "display_name": "Follow-Up Needed Checker",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "edited": true,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "bell-alert",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Follow-Up Message",
                "hidden": false,
                "method": "build_output",
                "name": "output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\r\nfrom langflow.io import MessageTextInput, Output\r\nfrom langflow.schema import Message\r\nimport json\r\n\r\nclass FollowUpCheckComponent(Component):\r\n    display_name = \"Follow-Up Needed Checker\"\r\n    description = \"Extracts 'follow_up_needed' from input and returns it as a Message.\"\r\n    documentation: str = \"https://docs.langflow.org/components-custom-components\"\r\n    icon = \"bell-alert\"\r\n    name = \"FollowUpNeededChecker\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"input_value\",\r\n            display_name=\"Adherence JSON\",\r\n            info=\"Provide a JSON string with adherence_rate, non_adherence_flag, and follow_up_needed.\",\r\n            value='{\"adherence_rate\": \"50%\", \"non_adherence_flag\": true, \"follow_up_needed\": true}',\r\n            tool_mode=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Follow-Up Message\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        try:\r\n            # Parse input\r\n            raw_data = self.input_value\r\n            if isinstance(raw_data, str):\r\n                data = json.loads(raw_data)\r\n            else:\r\n                data = raw_data\r\n\r\n            # Extract follow_up_needed\r\n            follow_up = data.get(\"follow_up_needed\", None)\r\n\r\n            # Format output\r\n            result_text = str(follow_up) if follow_up is not None else \"Key 'follow_up_needed' not found.\"\r\n\r\n        except Exception as e:\r\n            result_text = f\"Error parsing input: {e}\"\r\n\r\n        return Message(text=result_text)\r\n"
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Adherence JSON",
                "dynamic": false,
                "info": "Provide a JSON string with adherence_rate, non_adherence_flag, and follow_up_needed.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "FollowUpNeededChecker"
        },
        "id": "FollowUpNeededChecker-Oa4vB",
        "measured": {
          "height": 249,
          "width": 320
        },
        "position": {
          "x": 3622.199140326232,
          "y": 936.1273554718404
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": 97.31888368887655,
      "y": 197.84364056323088,
      "zoom": 0.21870532525880143
    }
  },
  "description": "Analyzes patient task reports to accurately calculate adherence rate, flag non-compliance, and trigger follow-up actions.",
  "endpoint_name": null,
  "id": "e334434f-2f05-4b4e-b7f6-58e6c5e47559",
  "is_component": false,
  "last_tested_version": "1.4.3",
  "name": "Adherence_Checker_Agent",
  "tags": []
}